{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connectionist Bench (Sonar, Mines vs. Rocks) Data Set\n",
    "\n",
    "Source:\n",
    "\n",
    "The data set was contributed to the benchmark collection by Terry Sejnowski, now at the Salk Institute and the University of California at San Deigo. The data set was developed in collaboration with R. Paul Gorman of Allied-Signal Aerospace Technology Center.\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. The file \"sonar.rocks\" contains 97 patterns obtained from rocks under similar conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\n",
    "\n",
    "Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
    "\n",
    "The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar = pd.read_csv(r'sonar.all-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0052  0.0044   R  \n",
       "1  0.0095  0.0078   R  \n",
       "2  0.0040  0.0117   R  \n",
       "3  0.0107  0.0094   R  \n",
       "4  0.0051  0.0062   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHODOLOGY: \t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "This data set can be used in a number of different ways to test learning\t\t\t\t\t\t\n",
    "speed\t quality of ultimate learning\t ability to generalize\t or combinations\t\t\t\n",
    "of these factors.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "In [1]\t Gorman and Sejnowski report two series of experiments: an\t\t\t\t\t\n",
    "aspect-angle independent\" series, in which the whole data set is used without controlling for aspect angle, and an \"aspect-angle dependent\t\t\t\t\t\t\n",
    "series in which the training and testing sets were carefully controlled to\t\t\t\t\t\t\n",
    "ensure that each set contained cases from each aspect angle in\t\t\t\t\t\t\n",
    "appropriate proportions.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "For the aspect-angle independent experiments the combined set of 208 cases\t\t\t\t\t\t\n",
    "is divided randomly into 13 disjoint sets with 16 cases in each.  For each\t\t\t\t\t\t\n",
    "experiment\t 12 of these sets are used as training data\t while the 13th is\t\t\t\t\n",
    "reserved for testing.  The experiment is repeated 13 times so that every\t\t\t\t\t\t\n",
    "case appears once as part of a test set.  The reported performance is an\t\t\t\t\t\t\n",
    "average over the entire set of 13 different test sets\t each run 10 times.\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "It was observed that this random division of the sample set led to rather\t\t\t\t\t\t\n",
    "uneven performance.  A few of the splits gave poor results\t presumably\t\t\t\t\t\n",
    "because the test set contains some samples from aspect angles that are\t\t\t\t\t\t\n",
    "under-represented in the corresponding training set.  This motivated Gorman\t\t\t\t\t\t\n",
    "and Sejnowski to devise a different set of experiments in which an attempt\t\t\t\t\t\t\n",
    "was made to balance the training and test sets so that each would have a\t\t\t\t\t\t\n",
    "representative number of samples from all aspect angles.  Since detailed\t\t\t\t\t\t\n",
    "aspect angle information was not present in the data base of samples\t the\t\t\t\t\t\n",
    "208 samples were first divided into clusters\t using a 60-dimensional\t\t\t\t\t\n",
    "Euclidian metric\t each of these clusters was then divided between the\t\t\t\t\t\n",
    "104-member training set and the 104-member test set.  \t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "The actual training and testing samples used for the \"aspect angle\t\t\t\t\t\t\n",
    "dependent\" experiments are marked in the data files.  The reported\t\t\t\t\t\t\n",
    "performance is an average over 10 runs with this single division of the\t\t\t\t\t\t\n",
    "data set.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "A standard back-propagation network was used for all experiments.  The\t\t\t\t\t\t\n",
    "network had 60 inputs and 2 output units\t one indicating a cylinder and the\t\t\t\t\t\n",
    "other a rock.  Experiments were run with no hidden units (direct\t\t\t\t\t\t\n",
    "connections from each input to each output) and with a single hidden layer\t\t\t\t\t\t\n",
    "with 2\t3\t6\t12\t or 24 units.  Each network was trained by 300 epochs over\t\t\n",
    "the entire training set.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "The weight-update formulas used in this study were slightly different from\t\t\t\t\t\t\n",
    "the standard form.  A learning rate of 2.0 and momentum of 0.0 was used.\t\t\t\t\t\t\n",
    "Errors less than 0.2 were treated as zero.  Initial weights were uniform\t\t\t\t\t\t\n",
    "random values in the range -0.3 to +0.3.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "RESULTS: \t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "For the angle independent experiments\t Gorman and Sejnowski report the\t\t\t\t\t\n",
    "following results for networks with different numbers of hidden units:\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "Hidden\t% Right on\tStd.\t% Right on\tStd.\t\t\n",
    "Units\tTraining set\tDev.\tTest Set\tDev.\t\t\n",
    "------\t------------\t----\t----------\t----\t\t\n",
    "0\t89.4\t\t2.1\t77.1\t\t8.3\n",
    "2\t96.5\t\t0.7\t81.9\t\t6.2\n",
    "3\t98.8\t\t0.4\t82\t\t7.3\n",
    "6\t99.7\t\t0.2\t83.5\t\t5.6\n",
    "12\t99.8\t\t0.1\t84.7\t\t5.7\n",
    "24\t99.8\t\t0.1\t84.5\t\t5.7\n",
    "\t\t\t\t\t\t\n",
    "For the angle-dependent experiments Gorman and Sejnowski report the\t\t\t\t\t\t\n",
    "following results:\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "Hidden\t% Right on\tStd.\t% Right on\tStd.\t\t\n",
    "Units\tTraining set\tDev.\tTest Set\tDev.\t\t\n",
    "------\t------------\t----\t----------\t----\t\t\n",
    "0\t79.3\t\t3.4\t73.1\t\t4.8\n",
    "2\t96.2\t\t2.2\t85.7\t\t6.3\n",
    "3\t98.1\t\t1.5\t87.6\t\t3\n",
    "6\t99.4\t\t0.9\t89.3\t\t2.4\n",
    "12\t99.8\t\t0.6\t90.4\t\t1.8\n",
    "24     100.0\t\t0\t89.2\t\t1.4\t\n",
    "\t\t\t\t\t\t\n",
    "Not surprisingly\t the network's performance on the test set was somewhat\t\t\t\t\t\n",
    "better when the aspect angles in the training and test sets were balanced.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "Gorman and Sejnowski further report that a nearest neighbor classifier on\t\t\t\t\t\t\n",
    "the same data gave an 82.7% probability of correct classification.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "Three trained human subjects were each tested on 100 signals\t chosen at\t\t\t\t\t\n",
    "random from the set of 208 returns used to create this data set.  Their\t\t\t\t\t\t\n",
    "responses ranged between 88% and 97% correct.  However\t they may have been\t\t\t\t\t\n",
    "using information from the raw sonar signal that is not preserved in the\t\t\t\t\t\t\n",
    "processed data sets presented here.\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "REFERENCES: \t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "1. Gorman\t R. P.\t and Sejnowski\t T. J. (1988).  \"Analysis of Hidden Units\t\t\t\n",
    "in a Layered Network Trained to Classify Sonar Targets\" in Neural Networks\t\t\t\t\t\t\n",
    "Vol. 1\t pp. 75-89.\t\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       207 non-null    float64\n",
      " 1   1       207 non-null    float64\n",
      " 2   2       207 non-null    float64\n",
      " 3   3       207 non-null    float64\n",
      " 4   4       207 non-null    float64\n",
      " 5   5       207 non-null    float64\n",
      " 6   6       207 non-null    float64\n",
      " 7   7       207 non-null    float64\n",
      " 8   8       207 non-null    float64\n",
      " 9   9       207 non-null    float64\n",
      " 10  10      207 non-null    float64\n",
      " 11  11      207 non-null    float64\n",
      " 12  12      207 non-null    float64\n",
      " 13  13      207 non-null    float64\n",
      " 14  14      207 non-null    float64\n",
      " 15  15      207 non-null    float64\n",
      " 16  16      207 non-null    float64\n",
      " 17  17      207 non-null    float64\n",
      " 18  18      207 non-null    float64\n",
      " 19  19      207 non-null    float64\n",
      " 20  20      207 non-null    float64\n",
      " 21  21      207 non-null    float64\n",
      " 22  22      207 non-null    float64\n",
      " 23  23      207 non-null    float64\n",
      " 24  24      207 non-null    float64\n",
      " 25  25      207 non-null    float64\n",
      " 26  26      207 non-null    float64\n",
      " 27  27      207 non-null    float64\n",
      " 28  28      207 non-null    float64\n",
      " 29  29      207 non-null    float64\n",
      " 30  30      207 non-null    float64\n",
      " 31  31      207 non-null    float64\n",
      " 32  32      207 non-null    float64\n",
      " 33  33      207 non-null    float64\n",
      " 34  34      207 non-null    float64\n",
      " 35  35      207 non-null    float64\n",
      " 36  36      207 non-null    float64\n",
      " 37  37      207 non-null    float64\n",
      " 38  38      207 non-null    float64\n",
      " 39  39      207 non-null    float64\n",
      " 40  40      207 non-null    float64\n",
      " 41  41      207 non-null    float64\n",
      " 42  42      207 non-null    float64\n",
      " 43  43      207 non-null    float64\n",
      " 44  44      207 non-null    float64\n",
      " 45  45      207 non-null    float64\n",
      " 46  46      207 non-null    float64\n",
      " 47  47      207 non-null    float64\n",
      " 48  48      207 non-null    float64\n",
      " 49  49      207 non-null    float64\n",
      " 50  50      207 non-null    float64\n",
      " 51  51      207 non-null    float64\n",
      " 52  52      207 non-null    float64\n",
      " 53  53      207 non-null    float64\n",
      " 54  54      207 non-null    float64\n",
      " 55  55      207 non-null    float64\n",
      " 56  56      207 non-null    float64\n",
      " 57  57      207 non-null    float64\n",
      " 58  58      207 non-null    float64\n",
      " 59  59      207 non-null    float64\n",
      " 60  60      207 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sonar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar.groupby(60).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sonar.values[:,0:-1]\n",
    "y = sonar.values[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Accuracy: \n",
      " 0.7142857142857143\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.82      0.69      0.75        26\n",
      "           R       0.60      0.75      0.67        16\n",
      "\n",
      "    accuracy                           0.71        42\n",
      "   macro avg       0.71      0.72      0.71        42\n",
      "weighted avg       0.74      0.71      0.72        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[18  8]\n",
      " [ 4 12]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Accuracy: \n",
      " 0.7619047619047619\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.86      0.73      0.79        26\n",
      "           R       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.76        42\n",
      "   macro avg       0.76      0.77      0.76        42\n",
      "weighted avg       0.78      0.76      0.77        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[19  7]\n",
      " [ 3 13]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Accuracy: \n",
      " 0.7619047619047619\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.86      0.73      0.79        26\n",
      "           R       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.76        42\n",
      "   macro avg       0.76      0.77      0.76        42\n",
      "weighted avg       0.78      0.76      0.77        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[19  7]\n",
      " [ 3 13]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Accuracy: \n",
      " 0.7857142857142857\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.84      0.81      0.82        26\n",
      "           R       0.71      0.75      0.73        16\n",
      "\n",
      "    accuracy                           0.79        42\n",
      "   macro avg       0.77      0.78      0.78        42\n",
      "weighted avg       0.79      0.79      0.79        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[21  5]\n",
      " [ 4 12]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Accuracy: \n",
      " 0.6428571428571429\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.87      0.50      0.63        26\n",
      "           R       0.52      0.88      0.65        16\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.69      0.69      0.64        42\n",
      "weighted avg       0.73      0.64      0.64        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[13 13]\n",
      " [ 2 14]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=False, tol=0.0001)\n",
      "Accuracy: \n",
      " 0.7142857142857143\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.85      0.65      0.74        26\n",
      "           R       0.59      0.81      0.68        16\n",
      "\n",
      "    accuracy                           0.71        42\n",
      "   macro avg       0.72      0.73      0.71        42\n",
      "weighted avg       0.75      0.71      0.72        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[17  9]\n",
      " [ 3 13]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Accuracy: \n",
      " 0.8333333333333334\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.91      0.81      0.86        26\n",
      "           R       0.74      0.88      0.80        16\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.82      0.84      0.83        42\n",
      "weighted avg       0.85      0.83      0.84        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[21  5]\n",
      " [ 2 14]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Accuracy: \n",
      " 0.9047619047619048\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.89      0.96      0.93        26\n",
      "           R       0.93      0.81      0.87        16\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.91      0.89      0.90        42\n",
      "weighted avg       0.91      0.90      0.90        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[25  1]\n",
      " [ 3 13]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Accuracy: \n",
      " 0.9285714285714286\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.93      0.96      0.94        26\n",
      "           R       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.93      0.92      0.92        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[25  1]\n",
      " [ 2 14]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model name: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Accuracy: \n",
      " 0.9523809523809523\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.96      0.96      0.96        26\n",
      "           R       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.95      0.95        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n",
      "Confusion matrix: \n",
      " [[25  1]\n",
      " [ 1 15]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {'LR': LogisticRegression(), 'KNN':KNeighborsClassifier(),'DTC':DecisionTreeClassifier(),\n",
    "        'svm':SVC(),'naivebayes':GaussianNB(), 'LDA':LinearDiscriminantAnalysis(),\n",
    "        'AdaBC':AdaBoostClassifier(),'GraBoost':GradientBoostingClassifier(),\n",
    "         'RFC':RandomForestClassifier(), 'ETC':ExtraTreesClassifier()}\n",
    "\n",
    "for each in models:\n",
    "    model=models[each]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypred = model.predict(X_test)\n",
    "    print(f\"model name: {models[each]}\")\n",
    "    print(\"Accuracy: \\n\", accuracy_score(y_test, ypred))\n",
    "    print(\"Classification report: \\n\", classification_report(y_test, ypred))\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_test, ypred))\n",
    "    print(\"\\n\\n\\n\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the results, the best performing model here is ExtraTreesClassifier and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see if we can improve the acuracy of the above models using GridSearchCV and RandomisedSearchCV\n",
    "Also since the accuracy is dependant on sample size, we will use kfold cross validation method to improve our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV for LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0026001 , 0.00020018, 0.00019965, 0.04840341, 0.00020046,\n",
       "        0.00120006, 0.00599966, 0.00499997, 0.00900078, 0.00479946,\n",
       "        0.00020022, 0.        , 0.        , 0.        , 0.00019989,\n",
       "        0.        , 0.02720184, 0.06680403, 0.09740729, 0.01820126,\n",
       "        0.00260057, 0.00020032, 0.00019979, 0.0524025 , 0.        ,\n",
       "        0.00140038, 0.00519924, 0.00460062, 0.01160145, 0.00599985,\n",
       "        0.        , 0.00040035, 0.        , 0.        , 0.00019999,\n",
       "        0.        , 0.03280091, 0.0824059 , 0.09340606, 0.01800117,\n",
       "        0.00099993, 0.00019994, 0.00020008, 0.04020281, 0.00020041,\n",
       "        0.        , 0.01140056, 0.0062006 , 0.0126009 , 0.01040068,\n",
       "        0.00019994, 0.00020003, 0.        , 0.        , 0.00020008,\n",
       "        0.00019999, 0.05780449, 0.09600658, 0.11180696, 0.02720213]),\n",
       " 'std_fit_time': array([4.90193715e-04, 4.00352478e-04, 3.99303436e-04, 9.02517878e-03,\n",
       "        4.00924683e-04, 4.00018735e-04, 1.07261866e-06, 6.32339410e-04,\n",
       "        6.32259065e-04, 7.48800615e-04, 4.00447845e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.99780273e-04, 0.00000000e+00,\n",
       "        9.32637399e-03, 6.85294423e-03, 6.82942331e-03, 8.44804780e-03,\n",
       "        4.90391041e-04, 4.00638580e-04, 3.99589539e-04, 9.26526445e-03,\n",
       "        0.00000000e+00, 4.89474530e-04, 3.99685845e-04, 7.98988869e-04,\n",
       "        1.02006682e-03, 6.32032848e-04, 0.00000000e+00, 4.90330224e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.99971008e-04, 0.00000000e+00,\n",
       "        1.07768224e-02, 5.16165300e-03, 5.31467480e-03, 8.60263858e-03,\n",
       "        1.09776158e-06, 3.99875641e-04, 4.00161743e-04, 6.70612982e-03,\n",
       "        4.00829315e-04, 0.00000000e+00, 1.85475396e-03, 7.48251775e-04,\n",
       "        1.62493063e-03, 4.89181256e-04, 3.99875641e-04, 4.00066376e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.00161743e-04, 3.99971008e-04,\n",
       "        1.62909310e-02, 1.13856824e-02, 8.44862364e-03, 1.49726047e-02]),\n",
       " 'mean_score_time': array([0.0004003 , 0.        , 0.        , 0.00080018, 0.        ,\n",
       "        0.00020061, 0.00019989, 0.00040045, 0.00060034, 0.00060034,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0006    , 0.00060081, 0.00040064, 0.00039992,\n",
       "        0.00059958, 0.        , 0.        , 0.00020022, 0.        ,\n",
       "        0.00019989, 0.0004003 , 0.00079947, 0.00059972, 0.00020022,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00040026, 0.00060062, 0.00080094, 0.00040002,\n",
       "        0.        , 0.        , 0.        , 0.00040007, 0.        ,\n",
       "        0.        , 0.00060005, 0.00039997, 0.        , 0.00019994,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00059986, 0.00060091, 0.00040045, 0.00040007]),\n",
       " 'std_score_time': array([0.00049027, 0.        , 0.        , 0.00040009, 0.        ,\n",
       "        0.00040121, 0.00039978, 0.00049045, 0.00049017, 0.00049017,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0004899 , 0.00049056, 0.00049068, 0.0004898 ,\n",
       "        0.00048955, 0.        , 0.        , 0.00040045, 0.        ,\n",
       "        0.00039978, 0.00049027, 0.00039973, 0.00048967, 0.00040045,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00049021, 0.00049041, 0.00040047, 0.00048992,\n",
       "        0.        , 0.        , 0.        , 0.00048998, 0.        ,\n",
       "        0.        , 0.00048994, 0.00048986, 0.        , 0.00039988,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00048978, 0.00049064, 0.00049045, 0.00048998]),\n",
       " 'param_multi_class': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'ovr',\n",
       "                    'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr',\n",
       "                    'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr', 'ovr',\n",
       "                    'ovr', 'ovr', 'ovr', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial',\n",
       "                    'multinomial', 'multinomial', 'multinomial'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'none', 'none', 'none',\n",
       "                    'none', 'none', 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'elasticnet', 'none',\n",
       "                    'none', 'none', 'none', 'none', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'none', 'none', 'none', 'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'auto', 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'auto', 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'auto', 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'multi_class': 'auto', 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'multi_class': 'auto', 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'auto', 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'auto', 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'auto', 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'multi_class': 'auto', 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'multi_class': 'auto', 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'multi_class': 'ovr', 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'multinomial',\n",
       "   'penalty': 'elasticnet',\n",
       "   'solver': 'liblinear'},\n",
       "  {'multi_class': 'multinomial',\n",
       "   'penalty': 'elasticnet',\n",
       "   'solver': 'newton-cg'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.72727273,        nan,        nan, 0.63636364,        nan,\n",
       "        0.78787879, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.81818182, 0.78787879, 0.81818182,\n",
       "        0.72727273,        nan,        nan, 0.63636364,        nan,\n",
       "        0.78787879, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.81818182, 0.78787879, 0.81818182,\n",
       "               nan,        nan,        nan, 0.63636364,        nan,\n",
       "               nan, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.84848485, 0.81818182, 0.81818182]),\n",
       " 'split1_test_score': array([0.72727273,        nan,        nan, 0.72727273,        nan,\n",
       "        0.78787879, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.6969697 , 0.72727273, 0.72727273, 0.66666667,\n",
       "        0.72727273,        nan,        nan, 0.72727273,        nan,\n",
       "        0.78787879, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.6969697 , 0.72727273, 0.72727273, 0.66666667,\n",
       "               nan,        nan,        nan, 0.72727273,        nan,\n",
       "               nan, 0.75757576, 0.75757576, 0.75757576, 0.75757576,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.6969697 , 0.6969697 , 0.72727273, 0.66666667]),\n",
       " 'split2_test_score': array([0.75757576,        nan,        nan, 0.81818182,        nan,\n",
       "        0.75757576, 0.84848485, 0.84848485, 0.84848485, 0.84848485,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.66666667, 0.78787879, 0.75757576, 0.78787879,\n",
       "        0.75757576,        nan,        nan, 0.81818182,        nan,\n",
       "        0.75757576, 0.84848485, 0.84848485, 0.84848485, 0.84848485,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.66666667, 0.78787879, 0.75757576, 0.78787879,\n",
       "               nan,        nan,        nan, 0.81818182,        nan,\n",
       "               nan, 0.84848485, 0.84848485, 0.84848485, 0.84848485,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.66666667, 0.75757576, 0.78787879, 0.81818182]),\n",
       " 'split3_test_score': array([0.72727273,        nan,        nan, 0.6969697 ,        nan,\n",
       "        0.75757576, 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.84848485, 0.81818182, 0.81818182,\n",
       "        0.72727273,        nan,        nan, 0.6969697 ,        nan,\n",
       "        0.75757576, 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.84848485, 0.81818182, 0.81818182,\n",
       "               nan,        nan,        nan, 0.6969697 ,        nan,\n",
       "               nan, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.81818182, 0.78787879, 0.84848485, 0.84848485]),\n",
       " 'split4_test_score': array([0.6969697 ,        nan,        nan, 0.66666667,        nan,\n",
       "        0.75757576, 0.87878788, 0.87878788, 0.87878788, 0.87878788,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.72727273, 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.6969697 ,        nan,        nan, 0.66666667,        nan,\n",
       "        0.75757576, 0.87878788, 0.87878788, 0.87878788, 0.87878788,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.72727273, 0.66666667, 0.66666667, 0.66666667,\n",
       "               nan,        nan,        nan, 0.66666667,        nan,\n",
       "               nan, 0.87878788, 0.87878788, 0.87878788, 0.87878788,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.72727273, 0.66666667, 0.66666667, 0.63636364]),\n",
       " 'mean_test_score': array([0.72727273,        nan,        nan, 0.70909091,        nan,\n",
       "        0.76969697, 0.78787879, 0.78787879, 0.78787879, 0.78787879,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.74545455, 0.76969697, 0.75151515, 0.75151515,\n",
       "        0.72727273,        nan,        nan, 0.70909091,        nan,\n",
       "        0.76969697, 0.78787879, 0.78787879, 0.78787879, 0.78787879,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.74545455, 0.76969697, 0.75151515, 0.75151515,\n",
       "               nan,        nan,        nan, 0.70909091,        nan,\n",
       "               nan, 0.78181818, 0.78181818, 0.78181818, 0.78181818,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.74545455, 0.75151515, 0.76969697, 0.75757576]),\n",
       " 'std_test_score': array([0.01916532,        nan,        nan, 0.06239776,        nan,\n",
       "        0.01484539, 0.06639061, 0.06639061, 0.06639061, 0.06639061,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.06239776, 0.06527472, 0.0521353 , 0.07015659,\n",
       "        0.01916532,        nan,        nan, 0.06239776,        nan,\n",
       "        0.01484539, 0.06639061, 0.06639061, 0.06639061, 0.06639061,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.06239776, 0.06527472, 0.0521353 , 0.07015659,\n",
       "               nan,        nan,        nan, 0.06239776,        nan,\n",
       "               nan, 0.07521014, 0.07521014, 0.07521014, 0.07521014,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.06239776, 0.06470957, 0.06527472, 0.08782653]),\n",
       " 'rank_test_score': array([27, 34, 35, 29, 37, 13,  1,  1,  1,  1, 57, 50, 49, 48, 47, 46, 24,\n",
       "        15, 19, 19, 27, 58, 43, 29, 45, 13,  1,  1,  1,  1, 52, 59, 53, 54,\n",
       "        55, 56, 24, 15, 19, 19, 60, 44, 51, 29, 33, 39,  9,  9,  9,  9, 42,\n",
       "        32, 41, 36, 38, 40, 24, 19, 15, 18])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(LogisticRegression(max_iter=1000), {\n",
    "    'solver': ['liblinear', 'newton-cg', 'sag', 'saga' , 'lbfgs'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'multi_class' : ['auto', 'ovr', 'multinomial']},\n",
    "    cv = 5\n",
    "     )\n",
    "clf.fit(X_train, y_train)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'none', 'so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.027202</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'none', 'so...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.066804</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>auto</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'none', 'so...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.097407</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>auto</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'none', 'so...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.018201</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>auto</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'none', 'so...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.070157</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.052402</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'none', 'sol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.032801</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'none', 'sol...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.082406</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'none', 'sol...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.093406</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>ovr</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'none', 'sol...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>ovr</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'none', 'sol...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.070157</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.040203</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'non...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.057804</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'non...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'non...</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.064710</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.111807</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'non...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.027202</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'non...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.087827</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002600      0.000490         0.000400        0.000490   \n",
       "1        0.000200      0.000400         0.000000        0.000000   \n",
       "2        0.000200      0.000399         0.000000        0.000000   \n",
       "3        0.048403      0.009025         0.000800        0.000400   \n",
       "4        0.000200      0.000401         0.000000        0.000000   \n",
       "5        0.001200      0.000400         0.000201        0.000401   \n",
       "6        0.006000      0.000001         0.000200        0.000400   \n",
       "7        0.005000      0.000632         0.000400        0.000490   \n",
       "8        0.009001      0.000632         0.000600        0.000490   \n",
       "9        0.004799      0.000749         0.000600        0.000490   \n",
       "10       0.000200      0.000400         0.000000        0.000000   \n",
       "11       0.000000      0.000000         0.000000        0.000000   \n",
       "12       0.000000      0.000000         0.000000        0.000000   \n",
       "13       0.000000      0.000000         0.000000        0.000000   \n",
       "14       0.000200      0.000400         0.000000        0.000000   \n",
       "15       0.000000      0.000000         0.000000        0.000000   \n",
       "16       0.027202      0.009326         0.000600        0.000490   \n",
       "17       0.066804      0.006853         0.000601        0.000491   \n",
       "18       0.097407      0.006829         0.000401        0.000491   \n",
       "19       0.018201      0.008448         0.000400        0.000490   \n",
       "20       0.002601      0.000490         0.000600        0.000490   \n",
       "21       0.000200      0.000401         0.000000        0.000000   \n",
       "22       0.000200      0.000400         0.000000        0.000000   \n",
       "23       0.052402      0.009265         0.000200        0.000400   \n",
       "24       0.000000      0.000000         0.000000        0.000000   \n",
       "25       0.001400      0.000489         0.000200        0.000400   \n",
       "26       0.005199      0.000400         0.000400        0.000490   \n",
       "27       0.004601      0.000799         0.000799        0.000400   \n",
       "28       0.011601      0.001020         0.000600        0.000490   \n",
       "29       0.006000      0.000632         0.000200        0.000400   \n",
       "30       0.000000      0.000000         0.000000        0.000000   \n",
       "31       0.000400      0.000490         0.000000        0.000000   \n",
       "32       0.000000      0.000000         0.000000        0.000000   \n",
       "33       0.000000      0.000000         0.000000        0.000000   \n",
       "34       0.000200      0.000400         0.000000        0.000000   \n",
       "35       0.000000      0.000000         0.000000        0.000000   \n",
       "36       0.032801      0.010777         0.000400        0.000490   \n",
       "37       0.082406      0.005162         0.000601        0.000490   \n",
       "38       0.093406      0.005315         0.000801        0.000400   \n",
       "39       0.018001      0.008603         0.000400        0.000490   \n",
       "40       0.001000      0.000001         0.000000        0.000000   \n",
       "41       0.000200      0.000400         0.000000        0.000000   \n",
       "42       0.000200      0.000400         0.000000        0.000000   \n",
       "43       0.040203      0.006706         0.000400        0.000490   \n",
       "44       0.000200      0.000401         0.000000        0.000000   \n",
       "45       0.000000      0.000000         0.000000        0.000000   \n",
       "46       0.011401      0.001855         0.000600        0.000490   \n",
       "47       0.006201      0.000748         0.000400        0.000490   \n",
       "48       0.012601      0.001625         0.000000        0.000000   \n",
       "49       0.010401      0.000489         0.000200        0.000400   \n",
       "50       0.000200      0.000400         0.000000        0.000000   \n",
       "51       0.000200      0.000400         0.000000        0.000000   \n",
       "52       0.000000      0.000000         0.000000        0.000000   \n",
       "53       0.000000      0.000000         0.000000        0.000000   \n",
       "54       0.000200      0.000400         0.000000        0.000000   \n",
       "55       0.000200      0.000400         0.000000        0.000000   \n",
       "56       0.057804      0.016291         0.000600        0.000490   \n",
       "57       0.096007      0.011386         0.000601        0.000491   \n",
       "58       0.111807      0.008449         0.000400        0.000490   \n",
       "59       0.027202      0.014973         0.000400        0.000490   \n",
       "\n",
       "   param_multi_class param_penalty param_solver  \\\n",
       "0               auto            l1    liblinear   \n",
       "1               auto            l1    newton-cg   \n",
       "2               auto            l1          sag   \n",
       "3               auto            l1         saga   \n",
       "4               auto            l1        lbfgs   \n",
       "5               auto            l2    liblinear   \n",
       "6               auto            l2    newton-cg   \n",
       "7               auto            l2          sag   \n",
       "8               auto            l2         saga   \n",
       "9               auto            l2        lbfgs   \n",
       "10              auto    elasticnet    liblinear   \n",
       "11              auto    elasticnet    newton-cg   \n",
       "12              auto    elasticnet          sag   \n",
       "13              auto    elasticnet         saga   \n",
       "14              auto    elasticnet        lbfgs   \n",
       "15              auto          none    liblinear   \n",
       "16              auto          none    newton-cg   \n",
       "17              auto          none          sag   \n",
       "18              auto          none         saga   \n",
       "19              auto          none        lbfgs   \n",
       "20               ovr            l1    liblinear   \n",
       "21               ovr            l1    newton-cg   \n",
       "22               ovr            l1          sag   \n",
       "23               ovr            l1         saga   \n",
       "24               ovr            l1        lbfgs   \n",
       "25               ovr            l2    liblinear   \n",
       "26               ovr            l2    newton-cg   \n",
       "27               ovr            l2          sag   \n",
       "28               ovr            l2         saga   \n",
       "29               ovr            l2        lbfgs   \n",
       "30               ovr    elasticnet    liblinear   \n",
       "31               ovr    elasticnet    newton-cg   \n",
       "32               ovr    elasticnet          sag   \n",
       "33               ovr    elasticnet         saga   \n",
       "34               ovr    elasticnet        lbfgs   \n",
       "35               ovr          none    liblinear   \n",
       "36               ovr          none    newton-cg   \n",
       "37               ovr          none          sag   \n",
       "38               ovr          none         saga   \n",
       "39               ovr          none        lbfgs   \n",
       "40       multinomial            l1    liblinear   \n",
       "41       multinomial            l1    newton-cg   \n",
       "42       multinomial            l1          sag   \n",
       "43       multinomial            l1         saga   \n",
       "44       multinomial            l1        lbfgs   \n",
       "45       multinomial            l2    liblinear   \n",
       "46       multinomial            l2    newton-cg   \n",
       "47       multinomial            l2          sag   \n",
       "48       multinomial            l2         saga   \n",
       "49       multinomial            l2        lbfgs   \n",
       "50       multinomial    elasticnet    liblinear   \n",
       "51       multinomial    elasticnet    newton-cg   \n",
       "52       multinomial    elasticnet          sag   \n",
       "53       multinomial    elasticnet         saga   \n",
       "54       multinomial    elasticnet        lbfgs   \n",
       "55       multinomial          none    liblinear   \n",
       "56       multinomial          none    newton-cg   \n",
       "57       multinomial          none          sag   \n",
       "58       multinomial          none         saga   \n",
       "59       multinomial          none        lbfgs   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'multi_class': 'auto', 'penalty': 'l1', 'solv...           0.727273   \n",
       "1   {'multi_class': 'auto', 'penalty': 'l1', 'solv...                NaN   \n",
       "2   {'multi_class': 'auto', 'penalty': 'l1', 'solv...                NaN   \n",
       "3   {'multi_class': 'auto', 'penalty': 'l1', 'solv...           0.636364   \n",
       "4   {'multi_class': 'auto', 'penalty': 'l1', 'solv...                NaN   \n",
       "5   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.787879   \n",
       "6   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.757576   \n",
       "7   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.757576   \n",
       "8   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.757576   \n",
       "9   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.757576   \n",
       "10  {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "11  {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "12  {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "13  {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "14  {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "15  {'multi_class': 'auto', 'penalty': 'none', 'so...                NaN   \n",
       "16  {'multi_class': 'auto', 'penalty': 'none', 'so...           0.818182   \n",
       "17  {'multi_class': 'auto', 'penalty': 'none', 'so...           0.818182   \n",
       "18  {'multi_class': 'auto', 'penalty': 'none', 'so...           0.787879   \n",
       "19  {'multi_class': 'auto', 'penalty': 'none', 'so...           0.818182   \n",
       "20  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...           0.727273   \n",
       "21  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...                NaN   \n",
       "22  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...                NaN   \n",
       "23  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...           0.636364   \n",
       "24  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...                NaN   \n",
       "25  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.787879   \n",
       "26  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.757576   \n",
       "27  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.757576   \n",
       "28  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.757576   \n",
       "29  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.757576   \n",
       "30  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "31  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "32  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "33  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "34  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "35  {'multi_class': 'ovr', 'penalty': 'none', 'sol...                NaN   \n",
       "36  {'multi_class': 'ovr', 'penalty': 'none', 'sol...           0.818182   \n",
       "37  {'multi_class': 'ovr', 'penalty': 'none', 'sol...           0.818182   \n",
       "38  {'multi_class': 'ovr', 'penalty': 'none', 'sol...           0.787879   \n",
       "39  {'multi_class': 'ovr', 'penalty': 'none', 'sol...           0.818182   \n",
       "40  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "41  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "42  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "43  {'multi_class': 'multinomial', 'penalty': 'l1'...           0.636364   \n",
       "44  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "45  {'multi_class': 'multinomial', 'penalty': 'l2'...                NaN   \n",
       "46  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.757576   \n",
       "47  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.757576   \n",
       "48  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.757576   \n",
       "49  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.757576   \n",
       "50  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "51  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "52  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "53  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "54  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "55  {'multi_class': 'multinomial', 'penalty': 'non...                NaN   \n",
       "56  {'multi_class': 'multinomial', 'penalty': 'non...           0.818182   \n",
       "57  {'multi_class': 'multinomial', 'penalty': 'non...           0.848485   \n",
       "58  {'multi_class': 'multinomial', 'penalty': 'non...           0.818182   \n",
       "59  {'multi_class': 'multinomial', 'penalty': 'non...           0.818182   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.727273           0.757576           0.727273   \n",
       "1                 NaN                NaN                NaN   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.727273           0.818182           0.696970   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.787879           0.757576           0.757576   \n",
       "6            0.757576           0.848485           0.696970   \n",
       "7            0.757576           0.848485           0.696970   \n",
       "8            0.757576           0.848485           0.696970   \n",
       "9            0.757576           0.848485           0.696970   \n",
       "10                NaN                NaN                NaN   \n",
       "11                NaN                NaN                NaN   \n",
       "12                NaN                NaN                NaN   \n",
       "13                NaN                NaN                NaN   \n",
       "14                NaN                NaN                NaN   \n",
       "15                NaN                NaN                NaN   \n",
       "16           0.696970           0.666667           0.818182   \n",
       "17           0.727273           0.787879           0.848485   \n",
       "18           0.727273           0.757576           0.818182   \n",
       "19           0.666667           0.787879           0.818182   \n",
       "20           0.727273           0.757576           0.727273   \n",
       "21                NaN                NaN                NaN   \n",
       "22                NaN                NaN                NaN   \n",
       "23           0.727273           0.818182           0.696970   \n",
       "24                NaN                NaN                NaN   \n",
       "25           0.787879           0.757576           0.757576   \n",
       "26           0.757576           0.848485           0.696970   \n",
       "27           0.757576           0.848485           0.696970   \n",
       "28           0.757576           0.848485           0.696970   \n",
       "29           0.757576           0.848485           0.696970   \n",
       "30                NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33                NaN                NaN                NaN   \n",
       "34                NaN                NaN                NaN   \n",
       "35                NaN                NaN                NaN   \n",
       "36           0.696970           0.666667           0.818182   \n",
       "37           0.727273           0.787879           0.848485   \n",
       "38           0.727273           0.757576           0.818182   \n",
       "39           0.666667           0.787879           0.818182   \n",
       "40                NaN                NaN                NaN   \n",
       "41                NaN                NaN                NaN   \n",
       "42                NaN                NaN                NaN   \n",
       "43           0.727273           0.818182           0.696970   \n",
       "44                NaN                NaN                NaN   \n",
       "45                NaN                NaN                NaN   \n",
       "46           0.757576           0.848485           0.666667   \n",
       "47           0.757576           0.848485           0.666667   \n",
       "48           0.757576           0.848485           0.666667   \n",
       "49           0.757576           0.848485           0.666667   \n",
       "50                NaN                NaN                NaN   \n",
       "51                NaN                NaN                NaN   \n",
       "52                NaN                NaN                NaN   \n",
       "53                NaN                NaN                NaN   \n",
       "54                NaN                NaN                NaN   \n",
       "55                NaN                NaN                NaN   \n",
       "56           0.696970           0.666667           0.818182   \n",
       "57           0.696970           0.757576           0.787879   \n",
       "58           0.727273           0.787879           0.848485   \n",
       "59           0.666667           0.818182           0.848485   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.696970         0.727273        0.019165               27  \n",
       "1                 NaN              NaN             NaN               34  \n",
       "2                 NaN              NaN             NaN               35  \n",
       "3            0.666667         0.709091        0.062398               29  \n",
       "4                 NaN              NaN             NaN               37  \n",
       "5            0.757576         0.769697        0.014845               13  \n",
       "6            0.878788         0.787879        0.066391                1  \n",
       "7            0.878788         0.787879        0.066391                1  \n",
       "8            0.878788         0.787879        0.066391                1  \n",
       "9            0.878788         0.787879        0.066391                1  \n",
       "10                NaN              NaN             NaN               57  \n",
       "11                NaN              NaN             NaN               50  \n",
       "12                NaN              NaN             NaN               49  \n",
       "13                NaN              NaN             NaN               48  \n",
       "14                NaN              NaN             NaN               47  \n",
       "15                NaN              NaN             NaN               46  \n",
       "16           0.727273         0.745455        0.062398               24  \n",
       "17           0.666667         0.769697        0.065275               15  \n",
       "18           0.666667         0.751515        0.052135               19  \n",
       "19           0.666667         0.751515        0.070157               19  \n",
       "20           0.696970         0.727273        0.019165               27  \n",
       "21                NaN              NaN             NaN               58  \n",
       "22                NaN              NaN             NaN               43  \n",
       "23           0.666667         0.709091        0.062398               29  \n",
       "24                NaN              NaN             NaN               45  \n",
       "25           0.757576         0.769697        0.014845               13  \n",
       "26           0.878788         0.787879        0.066391                1  \n",
       "27           0.878788         0.787879        0.066391                1  \n",
       "28           0.878788         0.787879        0.066391                1  \n",
       "29           0.878788         0.787879        0.066391                1  \n",
       "30                NaN              NaN             NaN               52  \n",
       "31                NaN              NaN             NaN               59  \n",
       "32                NaN              NaN             NaN               53  \n",
       "33                NaN              NaN             NaN               54  \n",
       "34                NaN              NaN             NaN               55  \n",
       "35                NaN              NaN             NaN               56  \n",
       "36           0.727273         0.745455        0.062398               24  \n",
       "37           0.666667         0.769697        0.065275               15  \n",
       "38           0.666667         0.751515        0.052135               19  \n",
       "39           0.666667         0.751515        0.070157               19  \n",
       "40                NaN              NaN             NaN               60  \n",
       "41                NaN              NaN             NaN               44  \n",
       "42                NaN              NaN             NaN               51  \n",
       "43           0.666667         0.709091        0.062398               29  \n",
       "44                NaN              NaN             NaN               33  \n",
       "45                NaN              NaN             NaN               39  \n",
       "46           0.878788         0.781818        0.075210                9  \n",
       "47           0.878788         0.781818        0.075210                9  \n",
       "48           0.878788         0.781818        0.075210                9  \n",
       "49           0.878788         0.781818        0.075210                9  \n",
       "50                NaN              NaN             NaN               42  \n",
       "51                NaN              NaN             NaN               32  \n",
       "52                NaN              NaN             NaN               41  \n",
       "53                NaN              NaN             NaN               36  \n",
       "54                NaN              NaN             NaN               38  \n",
       "55                NaN              NaN             NaN               40  \n",
       "56           0.727273         0.745455        0.062398               24  \n",
       "57           0.666667         0.751515        0.064710               19  \n",
       "58           0.666667         0.769697        0.065275               15  \n",
       "59           0.636364         0.757576        0.087827               18  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_multi_class param_penalty param_solver  mean_test_score\n",
       "27               ovr            l2          sag         0.787879\n",
       "8               auto            l2         saga         0.787879\n",
       "26               ovr            l2    newton-cg         0.787879\n",
       "29               ovr            l2        lbfgs         0.787879\n",
       "9               auto            l2        lbfgs         0.787879\n",
       "28               ovr            l2         saga         0.787879\n",
       "7               auto            l2          sag         0.787879\n",
       "6               auto            l2    newton-cg         0.787879\n",
       "49       multinomial            l2        lbfgs         0.781818\n",
       "48       multinomial            l2         saga         0.781818"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_multi_class','param_penalty', 'param_solver','mean_test_score']].sort_values(by='mean_test_score', ascending=False).dropna().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "{'multi_class': 'auto', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, previously when we ran this model using the default parameters we obtained the accuracy of 71.43% for Logistic Regression model. But if we tune the parameters, we obtain the accuracy of 78.78%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we will use GridSearchcv for rest of the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For model KNN, GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00199924, 0.0013998 , 0.00140028, 0.0012002 , 0.00100079,\n",
       "        0.0014008 , 0.00140004, 0.00100017, 0.00120082, 0.0012002 ,\n",
       "        0.00100069, 0.00120101, 0.00140028, 0.0012012 , 0.00140066,\n",
       "        0.0010004 , 0.00160046, 0.00100036, 0.00100131, 0.00119987,\n",
       "        0.00099983, 0.0010005 , 0.00099964, 0.00139985, 0.00140104,\n",
       "        0.00099983, 0.00099955, 0.00159998, 0.00080056, 0.00079951,\n",
       "        0.00140018, 0.00100069, 0.00100074, 0.00099993, 0.00100079,\n",
       "        0.00100031, 0.00100007, 0.00080009, 0.00099969, 0.00100031,\n",
       "        0.00120058, 0.00099921, 0.00120049, 0.00100093, 0.00100026,\n",
       "        0.00139971, 0.00119958, 0.00099959, 0.0015995 , 0.00119996,\n",
       "        0.001401  , 0.0012001 , 0.00120058, 0.00140066, 0.00120029,\n",
       "        0.00120049, 0.0012001 , 0.00120049, 0.00140095, 0.00099998,\n",
       "        0.00120125, 0.00119987, 0.00100026, 0.00100002, 0.00099926,\n",
       "        0.00159926, 0.00180049, 0.00160131, 0.00159302, 0.00119934,\n",
       "        0.00100007, 0.00140071, 0.0010005 , 0.00100126, 0.00100098,\n",
       "        0.00100107, 0.00120044, 0.00099926, 0.00100036, 0.00079875,\n",
       "        0.0010004 , 0.00099912, 0.00099983, 0.00099988, 0.00080061,\n",
       "        0.00099978, 0.00080051, 0.00080018, 0.00080018, 0.00100002,\n",
       "        0.0008007 , 0.00100017, 0.0010005 , 0.00080032, 0.00080061,\n",
       "        0.00080104, 0.00080147, 0.00100021, 0.00100002, 0.00099936,\n",
       "        0.00080032, 0.0010005 , 0.00140076, 0.00100064, 0.00120091,\n",
       "        0.00080075, 0.00100117, 0.00100083, 0.00080056, 0.00059967,\n",
       "        0.00100026, 0.00080028, 0.00139971, 0.00139971, 0.0012002 ,\n",
       "        0.00120001, 0.00119982, 0.00120106, 0.00140033, 0.00100026,\n",
       "        0.00120049, 0.00100074, 0.00160017, 0.00120101, 0.00120168,\n",
       "        0.00100045, 0.00120039, 0.00100064, 0.00139985, 0.00120034,\n",
       "        0.00140057, 0.00099988, 0.00100017, 0.0010006 , 0.00120053,\n",
       "        0.00140085, 0.00140123, 0.00100017, 0.00120015, 0.0013998 ,\n",
       "        0.0009995 , 0.00079966, 0.00100031, 0.00100117, 0.00079985,\n",
       "        0.00100045, 0.00100155, 0.00120106, 0.00100069, 0.00059938,\n",
       "        0.00100088, 0.00080028, 0.00100126, 0.00080085, 0.00080047,\n",
       "        0.00080032, 0.00100026, 0.00099998, 0.00120087, 0.00099978,\n",
       "        0.00099998, 0.00100064, 0.00080085, 0.00080018, 0.00100064,\n",
       "        0.00080032, 0.00079994, 0.0008007 , 0.00080013, 0.00040011,\n",
       "        0.00099998, 0.00080075, 0.00080032, 0.00080018, 0.00040002,\n",
       "        0.00100012, 0.00060039, 0.00079994, 0.00060062, 0.00040045,\n",
       "        0.00080061, 0.00080132, 0.00060019, 0.00100012, 0.00080047,\n",
       "        0.00079985, 0.00079942, 0.00059986, 0.00059977, 0.00079989,\n",
       "        0.0004005 , 0.00080018, 0.00080009, 0.00100021, 0.00060024,\n",
       "        0.00020003, 0.00060015, 0.00039949, 0.00080023, 0.00059929,\n",
       "        0.00060058, 0.00040011, 0.00080056, 0.00080018, 0.00060029,\n",
       "        0.00099964, 0.00080032, 0.00040021, 0.00060024, 0.00080066,\n",
       "        0.00079999, 0.00020003, 0.00060029, 0.00060058, 0.00039983,\n",
       "        0.00079999, 0.00040045, 0.00060043, 0.0004004 , 0.00080018,\n",
       "        0.0006001 , 0.00080051, 0.0006001 , 0.00060005]),\n",
       " 'std_fit_time': array([6.32259741e-04, 4.90038228e-04, 4.90330363e-04, 4.00066688e-04,\n",
       "        9.72560790e-07, 4.89220066e-04, 4.89843104e-04, 3.37174788e-07,\n",
       "        3.99995060e-04, 3.99470881e-04, 5.09122765e-07, 3.99661132e-04,\n",
       "        4.89453784e-04, 3.99685105e-04, 4.89336913e-04, 2.61174468e-07,\n",
       "        4.89843545e-04, 1.04904175e-06, 6.97552626e-07, 3.99995344e-04,\n",
       "        8.20381667e-07, 8.06404806e-07, 1.50336101e-06, 4.90680464e-04,\n",
       "        4.90388676e-04, 1.00701867e-06, 1.12436544e-06, 4.89941267e-04,\n",
       "        4.00282355e-04, 3.99757096e-04, 4.90117657e-04, 1.41773880e-06,\n",
       "        9.12243198e-07, 9.88790577e-07, 1.48203566e-06, 1.66961111e-06,\n",
       "        6.33164870e-04, 4.00043965e-04, 1.17770090e-06, 9.36836372e-07,\n",
       "        4.00711649e-04, 1.72586070e-06, 4.00519438e-04, 9.70220087e-07,\n",
       "        1.04033586e-06, 4.90311118e-04, 3.98826628e-04, 9.24621555e-07,\n",
       "        4.90721258e-04, 4.00070155e-04, 4.89746639e-04, 4.00954943e-04,\n",
       "        3.98326587e-04, 4.90310400e-04, 3.99542950e-04, 3.99805889e-04,\n",
       "        4.01432084e-04, 4.00878942e-04, 4.90661149e-04, 5.09122765e-07,\n",
       "        4.00735281e-04, 3.99164102e-04, 2.43140197e-07, 1.80065227e-06,\n",
       "        1.61984327e-06, 4.91304010e-04, 4.00401425e-04, 4.89473577e-04,\n",
       "        8.03708480e-04, 3.99543292e-04, 1.41130911e-06, 4.90173941e-04,\n",
       "        1.37871097e-06, 1.34532318e-06, 1.10395783e-06, 9.70220087e-07,\n",
       "        4.00425065e-04, 1.30935003e-06, 5.72204590e-07, 3.99375855e-04,\n",
       "        7.07263802e-07, 1.00701867e-06, 9.84180805e-07, 1.03814798e-06,\n",
       "        4.00306541e-04, 8.60951905e-07, 4.00259809e-04, 4.00091166e-04,\n",
       "        4.00090370e-04, 2.43140197e-07, 4.00355573e-04, 5.43678010e-07,\n",
       "        1.10395783e-06, 4.00162993e-04, 4.00304837e-04, 4.00520773e-04,\n",
       "        4.00735168e-04, 1.14242063e-06, 7.16843432e-07, 7.47889859e-07,\n",
       "        4.00165266e-04, 1.14440918e-06, 4.90232834e-04, 6.32486215e-04,\n",
       "        4.01377887e-04, 4.00376444e-04, 6.28991411e-07, 1.22872340e-06,\n",
       "        4.00281588e-04, 4.89628909e-04, 3.56832255e-07, 4.00138793e-04,\n",
       "        4.89628956e-04, 4.89629304e-04, 3.99710038e-04, 4.00283434e-04,\n",
       "        3.99900687e-04, 3.99279918e-04, 4.89707736e-04, 1.05120696e-06,\n",
       "        3.99565821e-04, 1.09361123e-06, 4.88636109e-04, 4.00020355e-04,\n",
       "        4.00163533e-04, 9.81867804e-07, 3.99852009e-04, 9.88790577e-07,\n",
       "        4.89220531e-04, 3.99756499e-04, 4.90001089e-04, 5.91739352e-07,\n",
       "        6.91002691e-07, 5.91739352e-07, 4.00735139e-04, 4.90544117e-04,\n",
       "        4.88870547e-04, 5.64201334e-07, 3.99017818e-04, 4.89453853e-04,\n",
       "        1.53331139e-06, 3.99828540e-04, 1.37044028e-06, 6.33239412e-04,\n",
       "        3.99924590e-04, 6.32409933e-04, 1.08106461e-06, 4.01306917e-04,\n",
       "        7.44843452e-07, 4.89396376e-04, 6.57274664e-07, 4.00138054e-04,\n",
       "        1.19304619e-06, 4.00424327e-04, 4.00233762e-04, 4.00164954e-04,\n",
       "        4.90933902e-07, 1.18155591e-06, 4.00090228e-04, 6.84390073e-07,\n",
       "        1.20064529e-06, 3.69356475e-07, 4.00428301e-04, 4.00090683e-04,\n",
       "        1.33173371e-06, 4.00164215e-04, 3.99973566e-04, 4.00353018e-04,\n",
       "        4.00066461e-04, 4.90037648e-04, 1.78416128e-07, 4.00377381e-04,\n",
       "        4.00161999e-04, 4.00090285e-04, 4.89920847e-04, 3.16297988e-07,\n",
       "        4.90213145e-04, 3.99971008e-04, 4.90408215e-04, 4.90446654e-04,\n",
       "        4.00305036e-04, 4.00662972e-04, 4.90057210e-04, 5.72204590e-07,\n",
       "        4.00233819e-04, 3.99923396e-04, 3.99709214e-04, 4.89784791e-04,\n",
       "        4.89706714e-04, 3.99947603e-04, 4.90505315e-04, 4.00091024e-04,\n",
       "        4.00043056e-04, 7.59953377e-07, 4.90096066e-04, 4.00066376e-04,\n",
       "        4.90018392e-04, 4.89278530e-04, 4.00114130e-04, 4.89317936e-04,\n",
       "        4.90368864e-04, 4.90037648e-04, 4.00282014e-04, 4.00090427e-04,\n",
       "        4.90136584e-04, 6.64157308e-07, 4.00161970e-04, 4.90154495e-04,\n",
       "        4.90096205e-04, 4.00329243e-04, 3.99995657e-04, 4.00066376e-04,\n",
       "        4.90135123e-04, 4.90368980e-04, 4.89687385e-04, 3.99994918e-04,\n",
       "        4.90446654e-04, 4.90252643e-04, 4.90388329e-04, 4.00090427e-04,\n",
       "        4.89979265e-04, 4.00257821e-04, 4.89979335e-04, 4.89940873e-04]),\n",
       " 'mean_score_time': array([0.00280066, 0.00160022, 0.00259995, 0.00119996, 0.00199943,\n",
       "        0.00119939, 0.00220051, 0.00139952, 0.00219975, 0.00119982,\n",
       "        0.00219965, 0.00139918, 0.00200009, 0.00119901, 0.00199938,\n",
       "        0.00119991, 0.00199966, 0.00100007, 0.00239916, 0.00159988,\n",
       "        0.00200119, 0.00119958, 0.00219994, 0.00100079, 0.00219908,\n",
       "        0.00200086, 0.00300093, 0.00140052, 0.00199966, 0.0010006 ,\n",
       "        0.00220022, 0.00099974, 0.00199947, 0.00120006, 0.00199952,\n",
       "        0.00140004, 0.00220051, 0.00120006, 0.00200472, 0.00099959,\n",
       "        0.00239882, 0.00139971, 0.002     , 0.0011992 , 0.00260019,\n",
       "        0.00120053, 0.00260096, 0.00140104, 0.00260005, 0.00140023,\n",
       "        0.00259929, 0.00099921, 0.00299969, 0.00139999, 0.00259962,\n",
       "        0.00140071, 0.00299883, 0.00159993, 0.0023994 , 0.0009995 ,\n",
       "        0.00279908, 0.00140023, 0.00280066, 0.0014008 , 0.00260043,\n",
       "        0.00180006, 0.00420051, 0.00139933, 0.00320039, 0.00180078,\n",
       "        0.00199971, 0.00140028, 0.00299888, 0.00139928, 0.00259905,\n",
       "        0.00139933, 0.00219927, 0.00139985, 0.00279961, 0.0012002 ,\n",
       "        0.00219951, 0.00099993, 0.00200052, 0.00119944, 0.00240002,\n",
       "        0.00119967, 0.00259895, 0.00120025, 0.00240006, 0.00119996,\n",
       "        0.00259953, 0.00119996, 0.00239944, 0.00120006, 0.00279927,\n",
       "        0.00119925, 0.00239835, 0.00119963, 0.00220013, 0.00140052,\n",
       "        0.00300007, 0.00119972, 0.00299921, 0.0013999 , 0.00259943,\n",
       "        0.00119944, 0.00239892, 0.00119963, 0.00240021, 0.00160041,\n",
       "        0.00239997, 0.00120015, 0.00240045, 0.00160055, 0.00199947,\n",
       "        0.00140023, 0.00220084, 0.00139985, 0.00259967, 0.00119944,\n",
       "        0.00199986, 0.00139966, 0.0019999 , 0.00139933, 0.00219874,\n",
       "        0.00099945, 0.00259981, 0.00119967, 0.00199995, 0.0012001 ,\n",
       "        0.00199919, 0.00120001, 0.00239916, 0.00119939, 0.00199933,\n",
       "        0.00139952, 0.00259919, 0.00180006, 0.00240059, 0.00100031,\n",
       "        0.00240045, 0.00120058, 0.00199971, 0.00119901, 0.00240049,\n",
       "        0.00119948, 0.00199852, 0.00159965, 0.00260048, 0.00160103,\n",
       "        0.00199909, 0.00120025, 0.00199909, 0.00139933, 0.00219946,\n",
       "        0.00120745, 0.00199995, 0.0010005 , 0.00199952, 0.00120039,\n",
       "        0.00200043, 0.00120001, 0.00199904, 0.00119977, 0.00199943,\n",
       "        0.00119987, 0.00219884, 0.00119996, 0.00219984, 0.00100031,\n",
       "        0.00200043, 0.00079956, 0.00199986, 0.00100017, 0.00220003,\n",
       "        0.00100026, 0.00240026, 0.0010005 , 0.00219989, 0.00119948,\n",
       "        0.0021997 , 0.00119929, 0.0023994 , 0.00120049, 0.00239906,\n",
       "        0.00099993, 0.00240021, 0.00080042, 0.00220032, 0.00120077,\n",
       "        0.00239987, 0.00099988, 0.002     , 0.00099998, 0.00219979,\n",
       "        0.0010005 , 0.00199986, 0.00100055, 0.00219989, 0.00080042,\n",
       "        0.00239959, 0.00100002, 0.0015995 , 0.00119944, 0.00219927,\n",
       "        0.00099978, 0.00159965, 0.00099998, 0.00239973, 0.00100017,\n",
       "        0.00219989, 0.00079951, 0.00239968, 0.00100017, 0.00219989,\n",
       "        0.00100021, 0.0021996 , 0.00099993, 0.00219979, 0.00120053,\n",
       "        0.00220041, 0.0009995 , 0.00200014, 0.00099959]),\n",
       " 'std_score_time': array([7.47933886e-04, 4.89552257e-04, 4.90662238e-04, 4.00186988e-04,\n",
       "        9.81867804e-07, 3.99518194e-04, 4.00233705e-04, 4.90076705e-04,\n",
       "        3.99780501e-04, 3.99900034e-04, 4.00662546e-04, 4.89862766e-04,\n",
       "        1.08735602e-06, 3.99589652e-04, 8.52992240e-07, 3.99971492e-04,\n",
       "        6.64157308e-07, 7.47889859e-07, 4.89823887e-04, 7.99822898e-04,\n",
       "        1.85047225e-06, 3.99542950e-04, 4.00519580e-04, 1.12436544e-06,\n",
       "        4.00591592e-04, 1.21943587e-06, 1.01601008e-06, 4.89551119e-04,\n",
       "        6.46813391e-07, 1.70198138e-06, 3.99661245e-04, 1.37706080e-06,\n",
       "        1.31972814e-06, 3.98946845e-04, 1.91092157e-06, 4.89454922e-04,\n",
       "        3.99637692e-04, 4.00376444e-04, 9.70173215e-06, 8.74056949e-07,\n",
       "        4.90389047e-04, 4.89630326e-04, 1.60007112e-06, 3.99734140e-04,\n",
       "        4.89299358e-04, 4.00615941e-04, 4.90116056e-04, 4.90875440e-04,\n",
       "        4.89571072e-04, 4.89687269e-04, 4.90408562e-04, 1.28834306e-06,\n",
       "        1.05120696e-06, 4.89787019e-04, 4.89902937e-04, 4.89204412e-04,\n",
       "        6.32259838e-04, 4.90000532e-04, 4.89922309e-04, 1.59152215e-06,\n",
       "        3.99494939e-04, 4.91732756e-04, 3.98612147e-04, 4.91362138e-04,\n",
       "        4.89200833e-04, 7.48073815e-04, 7.47489516e-04, 4.90621976e-04,\n",
       "        7.49770074e-04, 3.99829393e-04, 1.28480850e-06, 4.90623390e-04,\n",
       "        1.61280961e-06, 4.89200648e-04, 4.89727255e-04, 4.89259635e-04,\n",
       "        3.99542438e-04, 4.90194248e-04, 3.99995770e-04, 3.99828199e-04,\n",
       "        4.00138224e-04, 5.00111031e-07, 5.72204590e-07, 3.99613533e-04,\n",
       "        4.89123408e-04, 4.00090825e-04, 4.88481848e-04, 4.00520262e-04,\n",
       "        4.90057140e-04, 4.00066688e-04, 4.90020318e-04, 4.01139865e-04,\n",
       "        4.89590192e-04, 4.01211068e-04, 4.00543241e-04, 4.00663483e-04,\n",
       "        4.90583699e-04, 3.99876067e-04, 4.00066916e-04, 4.90719359e-04,\n",
       "        6.34071769e-04, 4.01141112e-04, 6.31204687e-04, 4.89280064e-04,\n",
       "        7.99932009e-04, 4.00209725e-04, 4.90310701e-04, 3.98803082e-04,\n",
       "        4.90525664e-04, 4.90097922e-04, 4.89453807e-04, 4.00686335e-04,\n",
       "        4.89940339e-04, 4.90115755e-04, 1.32831462e-06, 4.89882293e-04,\n",
       "        4.00067257e-04, 4.89512898e-04, 4.90233205e-04, 4.00329101e-04,\n",
       "        3.98950589e-07, 4.89474460e-04, 8.17605410e-07, 4.89455526e-04,\n",
       "        4.00996559e-04, 9.88790577e-07, 4.90350377e-04, 4.00331827e-04,\n",
       "        3.23406696e-07, 3.99756983e-04, 7.29420592e-07, 4.01234864e-04,\n",
       "        4.89629095e-04, 3.99875840e-04, 8.03580262e-07, 4.90368956e-04,\n",
       "        4.89356893e-04, 4.00306740e-04, 4.89727696e-04, 7.00804637e-07,\n",
       "        4.89454178e-04, 4.00712103e-04, 4.90933902e-07, 4.00545569e-04,\n",
       "        4.89709059e-04, 3.99113186e-04, 1.41934167e-06, 4.89668756e-04,\n",
       "        4.90313715e-04, 4.90702817e-04, 1.03814798e-06, 4.00162397e-04,\n",
       "        8.97163759e-07, 4.89843359e-04, 4.00042545e-04, 3.97639552e-04,\n",
       "        1.07261866e-06, 1.05120696e-06, 1.26698782e-06, 4.00329044e-04,\n",
       "        1.09361123e-06, 4.00401652e-04, 1.93457248e-06, 3.98971403e-04,\n",
       "        1.12234137e-06, 3.99637692e-04, 3.99876067e-04, 3.99948428e-04,\n",
       "        4.00328732e-04, 6.67572021e-07, 4.90933902e-07, 3.99781041e-04,\n",
       "        3.98950589e-07, 7.23159356e-07, 4.00352478e-04, 7.77697870e-07,\n",
       "        4.88734701e-04, 9.12243198e-07, 4.00187101e-04, 3.99828426e-04,\n",
       "        4.00877637e-04, 3.98731317e-04, 4.90116776e-04, 3.99684934e-04,\n",
       "        4.90291113e-04, 9.04734896e-07, 4.89842988e-04, 4.00209668e-04,\n",
       "        4.00209583e-04, 4.00496679e-04, 4.90602952e-04, 1.26519195e-06,\n",
       "        1.01824553e-06, 6.10649513e-07, 3.99518081e-04, 8.20381667e-07,\n",
       "        5.64201334e-07, 1.13443158e-06, 3.99470881e-04, 4.00210265e-04,\n",
       "        1.01977707e-03, 4.15696997e-07, 4.89162148e-04, 3.99374973e-04,\n",
       "        4.00376728e-04, 5.13569337e-07, 4.90252179e-04, 6.10649513e-07,\n",
       "        4.90330177e-04, 8.39558452e-07, 3.99947774e-04, 3.99757324e-04,\n",
       "        4.89492609e-04, 1.62404884e-06, 4.00066461e-04, 8.31393994e-07,\n",
       "        4.00090939e-04, 7.23159356e-07, 3.99876579e-04, 4.00138793e-04,\n",
       "        3.99565907e-04, 4.37028474e-07, 2.78041453e-07, 4.42200589e-07]),\n",
       " 'param_algorithm': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_leaf_size': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5,\n",
       "                    6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7,\n",
       "                    8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4,\n",
       "                    4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6,\n",
       "                    6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8,\n",
       "                    8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4,\n",
       "                    4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6,\n",
       "                    6, 7, 7, 8, 8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8,\n",
       "                    8, 9, 9, 10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 4,\n",
       "                    4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'leaf_size': 50,\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.75757576, 0.81818182, 0.81818182, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.78787879, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.72727273, 0.78787879, 0.6969697 , 0.78787879, 0.75757576,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.78787879, 0.81818182, 0.72727273, 0.81818182, 0.72727273,\n",
       "        0.78787879, 0.6969697 , 0.78787879, 0.75757576, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.72727273, 0.81818182, 0.78787879,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.72727273, 0.78787879,\n",
       "        0.6969697 , 0.78787879, 0.75757576, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.78787879, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.72727273, 0.78787879, 0.6969697 ,\n",
       "        0.78787879, 0.75757576, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.78787879, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.72727273, 0.78787879, 0.6969697 , 0.78787879,\n",
       "        0.75757576, 0.81818182, 0.81818182, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.78787879, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.72727273, 0.78787879, 0.6969697 , 0.78787879, 0.75757576,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.78787879, 0.81818182, 0.72727273, 0.81818182, 0.72727273,\n",
       "        0.78787879, 0.6969697 , 0.78787879, 0.75757576, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.72727273, 0.81818182, 0.78787879,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.72727273, 0.78787879,\n",
       "        0.6969697 , 0.78787879, 0.75757576, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.78787879, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.72727273, 0.78787879, 0.6969697 ,\n",
       "        0.78787879, 0.75757576, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.78787879, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.72727273, 0.78787879, 0.6969697 , 0.78787879,\n",
       "        0.75757576, 0.81818182, 0.81818182, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.78787879, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.72727273, 0.78787879, 0.6969697 , 0.78787879, 0.75757576,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.78787879, 0.81818182, 0.72727273, 0.81818182, 0.72727273,\n",
       "        0.78787879, 0.6969697 , 0.78787879, 0.75757576, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.72727273, 0.81818182, 0.78787879,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.72727273, 0.78787879,\n",
       "        0.6969697 , 0.78787879, 0.75757576, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.72727273, 0.81818182, 0.78787879, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.72727273, 0.78787879, 0.6969697 ,\n",
       "        0.78787879, 0.75757576, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.72727273, 0.81818182, 0.78787879, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.72727273, 0.78787879, 0.6969697 , 0.78787879,\n",
       "        0.75757576, 0.81818182, 0.81818182, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.78787879, 0.81818182, 0.72727273, 0.81818182,\n",
       "        0.72727273, 0.78787879, 0.6969697 , 0.78787879]),\n",
       " 'split1_test_score': array([0.72727273, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.81818182, 0.66666667, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.60606061, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.81818182,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.60606061, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.81818182, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.60606061, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.81818182, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.60606061, 0.6969697 , 0.60606061,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.81818182, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.60606061, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.81818182, 0.66666667, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.60606061, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.81818182,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.60606061, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.81818182, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.60606061, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.81818182, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.60606061, 0.6969697 , 0.60606061,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.81818182, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.60606061, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.81818182, 0.66666667, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.60606061, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.81818182,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.60606061, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.81818182, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.60606061, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.75757576, 0.72727273, 0.81818182, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.60606061, 0.6969697 , 0.60606061,\n",
       "        0.75757576, 0.72727273, 0.75757576, 0.72727273, 0.75757576,\n",
       "        0.72727273, 0.81818182, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.60606061, 0.75757576,\n",
       "        0.72727273, 0.75757576, 0.72727273, 0.75757576, 0.72727273,\n",
       "        0.81818182, 0.66666667, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.60606061, 0.75757576]),\n",
       " 'split2_test_score': array([0.78787879, 0.81818182, 0.87878788, 0.87878788, 0.6969697 ,\n",
       "        0.81818182, 0.57575758, 0.81818182, 0.57575758, 0.6969697 ,\n",
       "        0.57575758, 0.75757576, 0.60606061, 0.6969697 , 0.78787879,\n",
       "        0.81818182, 0.87878788, 0.87878788, 0.6969697 , 0.81818182,\n",
       "        0.57575758, 0.81818182, 0.57575758, 0.6969697 , 0.57575758,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.78787879, 0.81818182,\n",
       "        0.87878788, 0.87878788, 0.6969697 , 0.81818182, 0.57575758,\n",
       "        0.81818182, 0.57575758, 0.6969697 , 0.57575758, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.78787879, 0.81818182, 0.87878788,\n",
       "        0.87878788, 0.6969697 , 0.81818182, 0.57575758, 0.81818182,\n",
       "        0.57575758, 0.6969697 , 0.57575758, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.78787879, 0.81818182, 0.87878788, 0.87878788,\n",
       "        0.6969697 , 0.81818182, 0.57575758, 0.81818182, 0.57575758,\n",
       "        0.6969697 , 0.57575758, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.78787879, 0.81818182, 0.87878788, 0.87878788, 0.6969697 ,\n",
       "        0.81818182, 0.57575758, 0.81818182, 0.57575758, 0.6969697 ,\n",
       "        0.57575758, 0.75757576, 0.60606061, 0.6969697 , 0.78787879,\n",
       "        0.81818182, 0.87878788, 0.87878788, 0.6969697 , 0.81818182,\n",
       "        0.57575758, 0.81818182, 0.57575758, 0.6969697 , 0.57575758,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.78787879, 0.81818182,\n",
       "        0.87878788, 0.87878788, 0.6969697 , 0.81818182, 0.57575758,\n",
       "        0.81818182, 0.57575758, 0.6969697 , 0.57575758, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.78787879, 0.81818182, 0.87878788,\n",
       "        0.87878788, 0.6969697 , 0.81818182, 0.57575758, 0.81818182,\n",
       "        0.57575758, 0.6969697 , 0.57575758, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.78787879, 0.81818182, 0.87878788, 0.87878788,\n",
       "        0.6969697 , 0.81818182, 0.57575758, 0.81818182, 0.57575758,\n",
       "        0.6969697 , 0.57575758, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.78787879, 0.81818182, 0.87878788, 0.87878788, 0.6969697 ,\n",
       "        0.81818182, 0.57575758, 0.81818182, 0.57575758, 0.6969697 ,\n",
       "        0.57575758, 0.75757576, 0.60606061, 0.6969697 , 0.78787879,\n",
       "        0.81818182, 0.87878788, 0.87878788, 0.6969697 , 0.81818182,\n",
       "        0.57575758, 0.81818182, 0.57575758, 0.6969697 , 0.57575758,\n",
       "        0.75757576, 0.60606061, 0.6969697 , 0.78787879, 0.81818182,\n",
       "        0.87878788, 0.87878788, 0.6969697 , 0.81818182, 0.57575758,\n",
       "        0.81818182, 0.57575758, 0.6969697 , 0.57575758, 0.75757576,\n",
       "        0.60606061, 0.6969697 , 0.78787879, 0.81818182, 0.87878788,\n",
       "        0.87878788, 0.6969697 , 0.81818182, 0.57575758, 0.81818182,\n",
       "        0.57575758, 0.6969697 , 0.57575758, 0.75757576, 0.60606061,\n",
       "        0.6969697 , 0.78787879, 0.81818182, 0.87878788, 0.87878788,\n",
       "        0.6969697 , 0.81818182, 0.57575758, 0.81818182, 0.57575758,\n",
       "        0.6969697 , 0.57575758, 0.75757576, 0.60606061, 0.6969697 ,\n",
       "        0.78787879, 0.81818182, 0.87878788, 0.87878788, 0.6969697 ,\n",
       "        0.81818182, 0.57575758, 0.81818182, 0.57575758, 0.6969697 ,\n",
       "        0.57575758, 0.75757576, 0.60606061, 0.6969697 ]),\n",
       " 'split3_test_score': array([0.81818182, 0.81818182, 0.6969697 , 0.72727273, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.66666667, 0.63636364, 0.63636364,\n",
       "        0.54545455, 0.63636364, 0.57575758, 0.63636364, 0.81818182,\n",
       "        0.81818182, 0.6969697 , 0.72727273, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.66666667, 0.63636364, 0.63636364, 0.54545455,\n",
       "        0.63636364, 0.57575758, 0.63636364, 0.81818182, 0.81818182,\n",
       "        0.6969697 , 0.72727273, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.66666667, 0.63636364, 0.63636364, 0.54545455, 0.63636364,\n",
       "        0.57575758, 0.63636364, 0.81818182, 0.81818182, 0.6969697 ,\n",
       "        0.72727273, 0.66666667, 0.72727273, 0.63636364, 0.66666667,\n",
       "        0.63636364, 0.63636364, 0.54545455, 0.63636364, 0.57575758,\n",
       "        0.63636364, 0.81818182, 0.81818182, 0.6969697 , 0.72727273,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.66666667, 0.63636364,\n",
       "        0.63636364, 0.54545455, 0.63636364, 0.57575758, 0.63636364,\n",
       "        0.81818182, 0.81818182, 0.6969697 , 0.72727273, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.66666667, 0.63636364, 0.63636364,\n",
       "        0.54545455, 0.63636364, 0.57575758, 0.63636364, 0.81818182,\n",
       "        0.81818182, 0.6969697 , 0.72727273, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.66666667, 0.63636364, 0.63636364, 0.54545455,\n",
       "        0.63636364, 0.57575758, 0.63636364, 0.81818182, 0.81818182,\n",
       "        0.6969697 , 0.72727273, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.66666667, 0.63636364, 0.63636364, 0.54545455, 0.63636364,\n",
       "        0.57575758, 0.63636364, 0.81818182, 0.81818182, 0.6969697 ,\n",
       "        0.72727273, 0.66666667, 0.72727273, 0.63636364, 0.66666667,\n",
       "        0.63636364, 0.63636364, 0.54545455, 0.63636364, 0.57575758,\n",
       "        0.63636364, 0.81818182, 0.81818182, 0.6969697 , 0.72727273,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.66666667, 0.63636364,\n",
       "        0.63636364, 0.54545455, 0.63636364, 0.57575758, 0.63636364,\n",
       "        0.81818182, 0.81818182, 0.6969697 , 0.72727273, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.66666667, 0.63636364, 0.63636364,\n",
       "        0.54545455, 0.63636364, 0.57575758, 0.63636364, 0.81818182,\n",
       "        0.81818182, 0.6969697 , 0.72727273, 0.66666667, 0.72727273,\n",
       "        0.63636364, 0.66666667, 0.63636364, 0.63636364, 0.54545455,\n",
       "        0.63636364, 0.57575758, 0.63636364, 0.81818182, 0.81818182,\n",
       "        0.6969697 , 0.72727273, 0.66666667, 0.72727273, 0.63636364,\n",
       "        0.66666667, 0.63636364, 0.63636364, 0.54545455, 0.63636364,\n",
       "        0.57575758, 0.63636364, 0.81818182, 0.81818182, 0.6969697 ,\n",
       "        0.72727273, 0.66666667, 0.72727273, 0.63636364, 0.66666667,\n",
       "        0.63636364, 0.63636364, 0.54545455, 0.63636364, 0.57575758,\n",
       "        0.63636364, 0.81818182, 0.81818182, 0.6969697 , 0.72727273,\n",
       "        0.66666667, 0.72727273, 0.63636364, 0.66666667, 0.63636364,\n",
       "        0.63636364, 0.54545455, 0.63636364, 0.57575758, 0.63636364,\n",
       "        0.81818182, 0.81818182, 0.6969697 , 0.72727273, 0.66666667,\n",
       "        0.72727273, 0.63636364, 0.66666667, 0.63636364, 0.63636364,\n",
       "        0.54545455, 0.63636364, 0.57575758, 0.63636364]),\n",
       " 'split4_test_score': array([0.72727273, 0.72727273, 0.75757576, 0.75757576, 0.72727273,\n",
       "        0.78787879, 0.66666667, 0.72727273, 0.60606061, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.63636364, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.75757576, 0.75757576, 0.72727273, 0.78787879,\n",
       "        0.66666667, 0.72727273, 0.60606061, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.63636364, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.75757576, 0.75757576, 0.72727273, 0.78787879, 0.66666667,\n",
       "        0.72727273, 0.60606061, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.63636364, 0.72727273, 0.72727273, 0.72727273, 0.75757576,\n",
       "        0.75757576, 0.72727273, 0.78787879, 0.66666667, 0.72727273,\n",
       "        0.60606061, 0.72727273, 0.63636364, 0.75757576, 0.63636364,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.75757576, 0.75757576,\n",
       "        0.72727273, 0.78787879, 0.66666667, 0.72727273, 0.60606061,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.63636364, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.75757576, 0.75757576, 0.72727273,\n",
       "        0.78787879, 0.66666667, 0.72727273, 0.60606061, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.63636364, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.75757576, 0.75757576, 0.72727273, 0.78787879,\n",
       "        0.66666667, 0.72727273, 0.60606061, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.63636364, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.75757576, 0.75757576, 0.72727273, 0.78787879, 0.66666667,\n",
       "        0.72727273, 0.60606061, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.63636364, 0.72727273, 0.72727273, 0.72727273, 0.75757576,\n",
       "        0.75757576, 0.72727273, 0.78787879, 0.66666667, 0.72727273,\n",
       "        0.60606061, 0.72727273, 0.63636364, 0.75757576, 0.63636364,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.75757576, 0.75757576,\n",
       "        0.72727273, 0.78787879, 0.66666667, 0.72727273, 0.60606061,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.63636364, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.75757576, 0.75757576, 0.72727273,\n",
       "        0.78787879, 0.66666667, 0.72727273, 0.60606061, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.63636364, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.75757576, 0.75757576, 0.72727273, 0.78787879,\n",
       "        0.66666667, 0.72727273, 0.60606061, 0.72727273, 0.63636364,\n",
       "        0.75757576, 0.63636364, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.75757576, 0.75757576, 0.72727273, 0.78787879, 0.66666667,\n",
       "        0.72727273, 0.60606061, 0.72727273, 0.63636364, 0.75757576,\n",
       "        0.63636364, 0.72727273, 0.72727273, 0.72727273, 0.75757576,\n",
       "        0.75757576, 0.72727273, 0.78787879, 0.66666667, 0.72727273,\n",
       "        0.60606061, 0.72727273, 0.63636364, 0.75757576, 0.63636364,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.75757576, 0.75757576,\n",
       "        0.72727273, 0.78787879, 0.66666667, 0.72727273, 0.60606061,\n",
       "        0.72727273, 0.63636364, 0.75757576, 0.63636364, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.75757576, 0.75757576, 0.72727273,\n",
       "        0.78787879, 0.66666667, 0.72727273, 0.60606061, 0.72727273,\n",
       "        0.63636364, 0.75757576, 0.63636364, 0.72727273]),\n",
       " 'mean_test_score': array([0.76363636, 0.78787879, 0.77575758, 0.78787879, 0.70909091,\n",
       "        0.79393939, 0.66666667, 0.75151515, 0.63636364, 0.72727273,\n",
       "        0.61818182, 0.72727273, 0.62424242, 0.72121212, 0.76363636,\n",
       "        0.78787879, 0.77575758, 0.78787879, 0.70909091, 0.79393939,\n",
       "        0.66666667, 0.75151515, 0.63636364, 0.72727273, 0.61818182,\n",
       "        0.72727273, 0.62424242, 0.72121212, 0.76363636, 0.78787879,\n",
       "        0.77575758, 0.78787879, 0.70909091, 0.79393939, 0.66666667,\n",
       "        0.75151515, 0.63636364, 0.72727273, 0.61818182, 0.72727273,\n",
       "        0.62424242, 0.72121212, 0.76363636, 0.78787879, 0.77575758,\n",
       "        0.78787879, 0.70909091, 0.79393939, 0.66666667, 0.75151515,\n",
       "        0.63636364, 0.72727273, 0.61818182, 0.72727273, 0.62424242,\n",
       "        0.72121212, 0.76363636, 0.78787879, 0.77575758, 0.78787879,\n",
       "        0.70909091, 0.79393939, 0.66666667, 0.75151515, 0.63636364,\n",
       "        0.72727273, 0.61818182, 0.72727273, 0.62424242, 0.72121212,\n",
       "        0.76363636, 0.78787879, 0.77575758, 0.78787879, 0.70909091,\n",
       "        0.79393939, 0.66666667, 0.75151515, 0.63636364, 0.72727273,\n",
       "        0.61818182, 0.72727273, 0.62424242, 0.72121212, 0.76363636,\n",
       "        0.78787879, 0.77575758, 0.78787879, 0.70909091, 0.79393939,\n",
       "        0.66666667, 0.75151515, 0.63636364, 0.72727273, 0.61818182,\n",
       "        0.72727273, 0.62424242, 0.72121212, 0.76363636, 0.78787879,\n",
       "        0.77575758, 0.78787879, 0.70909091, 0.79393939, 0.66666667,\n",
       "        0.75151515, 0.63636364, 0.72727273, 0.61818182, 0.72727273,\n",
       "        0.62424242, 0.72121212, 0.76363636, 0.78787879, 0.77575758,\n",
       "        0.78787879, 0.70909091, 0.79393939, 0.66666667, 0.75151515,\n",
       "        0.63636364, 0.72727273, 0.61818182, 0.72727273, 0.62424242,\n",
       "        0.72121212, 0.76363636, 0.78787879, 0.77575758, 0.78787879,\n",
       "        0.70909091, 0.79393939, 0.66666667, 0.75151515, 0.63636364,\n",
       "        0.72727273, 0.61818182, 0.72727273, 0.62424242, 0.72121212,\n",
       "        0.76363636, 0.78787879, 0.77575758, 0.78787879, 0.70909091,\n",
       "        0.79393939, 0.66666667, 0.75151515, 0.63636364, 0.72727273,\n",
       "        0.61818182, 0.72727273, 0.62424242, 0.72121212, 0.76363636,\n",
       "        0.78787879, 0.77575758, 0.78787879, 0.70909091, 0.79393939,\n",
       "        0.66666667, 0.75151515, 0.63636364, 0.72727273, 0.61818182,\n",
       "        0.72727273, 0.62424242, 0.72121212, 0.76363636, 0.78787879,\n",
       "        0.77575758, 0.78787879, 0.70909091, 0.79393939, 0.66666667,\n",
       "        0.75151515, 0.63636364, 0.72727273, 0.61818182, 0.72727273,\n",
       "        0.62424242, 0.72121212, 0.76363636, 0.78787879, 0.77575758,\n",
       "        0.78787879, 0.70909091, 0.79393939, 0.66666667, 0.75151515,\n",
       "        0.63636364, 0.72727273, 0.61818182, 0.72727273, 0.62424242,\n",
       "        0.72121212, 0.76363636, 0.78787879, 0.77575758, 0.78787879,\n",
       "        0.70909091, 0.79393939, 0.66666667, 0.75151515, 0.63636364,\n",
       "        0.72727273, 0.61818182, 0.72727273, 0.62424242, 0.72121212,\n",
       "        0.76363636, 0.78787879, 0.77575758, 0.78787879, 0.70909091,\n",
       "        0.79393939, 0.66666667, 0.75151515, 0.63636364, 0.72727273,\n",
       "        0.61818182, 0.72727273, 0.62424242, 0.72121212]),\n",
       " 'std_test_score': array([0.0353391 , 0.03833064, 0.06527472, 0.05420771, 0.02424242,\n",
       "        0.0353391 , 0.06910154, 0.05875976, 0.05070667, 0.06060606,\n",
       "        0.06239776, 0.05420771, 0.04110503, 0.0521353 , 0.0353391 ,\n",
       "        0.03833064, 0.06527472, 0.05420771, 0.02424242, 0.0353391 ,\n",
       "        0.06910154, 0.05875976, 0.05070667, 0.06060606, 0.06239776,\n",
       "        0.05420771, 0.04110503, 0.0521353 , 0.0353391 , 0.03833064,\n",
       "        0.06527472, 0.05420771, 0.02424242, 0.0353391 , 0.06910154,\n",
       "        0.05875976, 0.05070667, 0.06060606, 0.06239776, 0.05420771,\n",
       "        0.04110503, 0.0521353 , 0.0353391 , 0.03833064, 0.06527472,\n",
       "        0.05420771, 0.02424242, 0.0353391 , 0.06910154, 0.05875976,\n",
       "        0.05070667, 0.06060606, 0.06239776, 0.05420771, 0.04110503,\n",
       "        0.0521353 , 0.0353391 , 0.03833064, 0.06527472, 0.05420771,\n",
       "        0.02424242, 0.0353391 , 0.06910154, 0.05875976, 0.05070667,\n",
       "        0.06060606, 0.06239776, 0.05420771, 0.04110503, 0.0521353 ,\n",
       "        0.0353391 , 0.03833064, 0.06527472, 0.05420771, 0.02424242,\n",
       "        0.0353391 , 0.06910154, 0.05875976, 0.05070667, 0.06060606,\n",
       "        0.06239776, 0.05420771, 0.04110503, 0.0521353 , 0.0353391 ,\n",
       "        0.03833064, 0.06527472, 0.05420771, 0.02424242, 0.0353391 ,\n",
       "        0.06910154, 0.05875976, 0.05070667, 0.06060606, 0.06239776,\n",
       "        0.05420771, 0.04110503, 0.0521353 , 0.0353391 , 0.03833064,\n",
       "        0.06527472, 0.05420771, 0.02424242, 0.0353391 , 0.06910154,\n",
       "        0.05875976, 0.05070667, 0.06060606, 0.06239776, 0.05420771,\n",
       "        0.04110503, 0.0521353 , 0.0353391 , 0.03833064, 0.06527472,\n",
       "        0.05420771, 0.02424242, 0.0353391 , 0.06910154, 0.05875976,\n",
       "        0.05070667, 0.06060606, 0.06239776, 0.05420771, 0.04110503,\n",
       "        0.0521353 , 0.0353391 , 0.03833064, 0.06527472, 0.05420771,\n",
       "        0.02424242, 0.0353391 , 0.06910154, 0.05875976, 0.05070667,\n",
       "        0.06060606, 0.06239776, 0.05420771, 0.04110503, 0.0521353 ,\n",
       "        0.0353391 , 0.03833064, 0.06527472, 0.05420771, 0.02424242,\n",
       "        0.0353391 , 0.06910154, 0.05875976, 0.05070667, 0.06060606,\n",
       "        0.06239776, 0.05420771, 0.04110503, 0.0521353 , 0.0353391 ,\n",
       "        0.03833064, 0.06527472, 0.05420771, 0.02424242, 0.0353391 ,\n",
       "        0.06910154, 0.05875976, 0.05070667, 0.06060606, 0.06239776,\n",
       "        0.05420771, 0.04110503, 0.0521353 , 0.0353391 , 0.03833064,\n",
       "        0.06527472, 0.05420771, 0.02424242, 0.0353391 , 0.06910154,\n",
       "        0.05875976, 0.05070667, 0.06060606, 0.06239776, 0.05420771,\n",
       "        0.04110503, 0.0521353 , 0.0353391 , 0.03833064, 0.06527472,\n",
       "        0.05420771, 0.02424242, 0.0353391 , 0.06910154, 0.05875976,\n",
       "        0.05070667, 0.06060606, 0.06239776, 0.05420771, 0.04110503,\n",
       "        0.0521353 , 0.0353391 , 0.03833064, 0.06527472, 0.05420771,\n",
       "        0.02424242, 0.0353391 , 0.06910154, 0.05875976, 0.05070667,\n",
       "        0.06060606, 0.06239776, 0.05420771, 0.04110503, 0.0521353 ,\n",
       "        0.0353391 , 0.03833064, 0.06527472, 0.05420771, 0.02424242,\n",
       "        0.0353391 , 0.06910154, 0.05875976, 0.05070667, 0.06060606,\n",
       "        0.06239776, 0.05420771, 0.04110503, 0.0521353 ]),\n",
       " 'rank_test_score': array([ 65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,  97, 193,\n",
       "        129,  65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,  97,\n",
       "        193, 129,  65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,\n",
       "         97, 193, 129,  65,  17,  49,  17, 145,   1, 161,  81, 177,  97,\n",
       "        209,  97, 193, 129,  65,  17,  49,  17, 145,   1, 161,  81, 177,\n",
       "         97, 209,  97, 193, 129,  65,  17,  49,  17, 145,   1, 161,  81,\n",
       "        177,  97, 209,  97, 193, 129,  65,  17,  49,  17, 145,   1, 161,\n",
       "         81, 177,  97, 209,  97, 193, 129,  65,  17,  49,  17, 145,   1,\n",
       "        161,  81, 177,  97, 209,  97, 193, 129,  65,  17,  49,  17, 145,\n",
       "          1, 161,  81, 177,  97, 209,  97, 193, 129,  65,  17,  49,  17,\n",
       "        145,   1, 161,  81, 177,  97, 209,  97, 193, 129,  65,  17,  49,\n",
       "         17, 145,   1, 161,  81, 177,  97, 209,  97, 193, 129,  65,  17,\n",
       "         49,  17, 145,   1, 161,  81, 177,  97, 209,  97, 193, 129,  65,\n",
       "         17,  49,  17, 145,   1, 161,  81, 177,  97, 209,  97, 193, 129,\n",
       "         65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,  97, 193,\n",
       "        129,  65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,  97,\n",
       "        193, 129,  65,  17,  49,  17, 145,   1, 161,  81, 177,  97, 209,\n",
       "         97, 193, 129])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(KNeighborsClassifier(), {\n",
    "    'n_neighbors' : [4,5,6,7,8,9,10],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' :['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size' : [20,30,40,50]},\n",
    "    cv = 5\n",
    "     )\n",
    "clf.fit(X_train, y_train)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_leaf_size</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>6.322597e-04</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>7.479339e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 20, 'n_neig...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.900382e-04</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.895523e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 20, 'n_neig...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.038331</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.903304e-04</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>4.906622e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 20, 'n_neig...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>4.000667e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>4.001870e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 20, 'n_neig...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.054208</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>9.725608e-07</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>9.818678e-07</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 20, 'n_neig...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>4.000904e-04</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>4.001388e-04</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 50, 'n_nei...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.899793e-04</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>3.995659e-04</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 50, 'n_nei...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>4.002578e-04</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>4.370285e-07</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 50, 'n_nei...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.054208</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.899793e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.780415e-07</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 50, 'n_nei...</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.041105</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.899409e-04</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.422006e-07</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 50, 'n_nei...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.001999  6.322597e-04         0.002801    7.479339e-04   \n",
       "1         0.001400  4.900382e-04         0.001600    4.895523e-04   \n",
       "2         0.001400  4.903304e-04         0.002600    4.906622e-04   \n",
       "3         0.001200  4.000667e-04         0.001200    4.001870e-04   \n",
       "4         0.001001  9.725608e-07         0.001999    9.818678e-07   \n",
       "..             ...           ...              ...             ...   \n",
       "219       0.000800  4.000904e-04         0.001201    4.001388e-04   \n",
       "220       0.000600  4.899793e-04         0.002200    3.995659e-04   \n",
       "221       0.000801  4.002578e-04         0.000999    4.370285e-07   \n",
       "222       0.000600  4.899793e-04         0.002000    2.780415e-07   \n",
       "223       0.000600  4.899409e-04         0.001000    4.422006e-07   \n",
       "\n",
       "    param_algorithm param_leaf_size param_n_neighbors param_weights  \\\n",
       "0              auto              20                 4       uniform   \n",
       "1              auto              20                 4      distance   \n",
       "2              auto              20                 5       uniform   \n",
       "3              auto              20                 5      distance   \n",
       "4              auto              20                 6       uniform   \n",
       "..              ...             ...               ...           ...   \n",
       "219           brute              50                 8      distance   \n",
       "220           brute              50                 9       uniform   \n",
       "221           brute              50                 9      distance   \n",
       "222           brute              50                10       uniform   \n",
       "223           brute              50                10      distance   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...           0.757576   \n",
       "1    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...           0.818182   \n",
       "2    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...           0.818182   \n",
       "3    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...           0.818182   \n",
       "4    {'algorithm': 'auto', 'leaf_size': 20, 'n_neig...           0.727273   \n",
       "..                                                 ...                ...   \n",
       "219  {'algorithm': 'brute', 'leaf_size': 50, 'n_nei...           0.818182   \n",
       "220  {'algorithm': 'brute', 'leaf_size': 50, 'n_nei...           0.727273   \n",
       "221  {'algorithm': 'brute', 'leaf_size': 50, 'n_nei...           0.787879   \n",
       "222  {'algorithm': 'brute', 'leaf_size': 50, 'n_nei...           0.696970   \n",
       "223  {'algorithm': 'brute', 'leaf_size': 50, 'n_nei...           0.787879   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.727273           0.787879           0.818182   \n",
       "1             0.757576           0.818182           0.818182   \n",
       "2             0.727273           0.878788           0.696970   \n",
       "3             0.757576           0.878788           0.727273   \n",
       "4             0.727273           0.696970           0.666667   \n",
       "..                 ...                ...                ...   \n",
       "219           0.757576           0.696970           0.636364   \n",
       "220           0.606061           0.575758           0.545455   \n",
       "221           0.696970           0.757576           0.636364   \n",
       "222           0.606061           0.606061           0.575758   \n",
       "223           0.757576           0.696970           0.636364   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.727273         0.763636        0.035339               65  \n",
       "1             0.727273         0.787879        0.038331               17  \n",
       "2             0.757576         0.775758        0.065275               49  \n",
       "3             0.757576         0.787879        0.054208               17  \n",
       "4             0.727273         0.709091        0.024242              145  \n",
       "..                 ...              ...             ...              ...  \n",
       "219           0.727273         0.727273        0.060606               97  \n",
       "220           0.636364         0.618182        0.062398              209  \n",
       "221           0.757576         0.727273        0.054208               97  \n",
       "222           0.636364         0.624242        0.041105              193  \n",
       "223           0.727273         0.721212        0.052135              129  \n",
       "\n",
       "[224 rows x 17 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=20, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "                     weights='distance') {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 6, 'weights': 'distance'} 0.793939393939394\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_,\n",
    "clf.best_params_,\n",
    "clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously for KNN model, we got accuracy as Accuracy: 0.7619047619047619, \n",
    "\n",
    "but with GridSearchCv we have better accuracy of 0.793939393939394 \n",
    "\n",
    "for best params {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 6, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR': LogisticRegression(), 'KNN':KNeighborsClassifier(),'DTC':DecisionTreeClassifier(),\n",
    "        'svm':SVC(),'naivebayes':GaussianNB(), 'LDA':LinearDiscriminantAnalysis(),\n",
    "        'AdaBC':AdaBoostClassifier(),'GraBoost':GradientBoostingClassifier(),\n",
    "         'RFC':RandomForestClassifier(), 'ETC':ExtraTreesClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.993697e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>int</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'int', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.079486e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>int</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'int', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>4.332076e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>float</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'float',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000625</td>\n",
       "      <td>4.845052e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>float</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'float',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>7.052517e-07</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>gini</td>\n",
       "      <td>auto</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.715476</td>\n",
       "      <td>0.102519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001000  4.993697e-04         0.000000        0.000000   \n",
       "1       0.001000  1.079486e-06         0.000000        0.000000   \n",
       "2       0.000750  4.332076e-04         0.000000        0.000000   \n",
       "3       0.000625  4.845052e-04         0.000000        0.000000   \n",
       "4       0.001000  7.052517e-07         0.000375        0.000484   \n",
       "\n",
       "  param_criterion param_max_features param_splitter  \\\n",
       "0            gini                int           best   \n",
       "1            gini                int         random   \n",
       "2            gini              float           best   \n",
       "3            gini              float         random   \n",
       "4            gini               auto           best   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_features': 'int', '...                NaN   \n",
       "1  {'criterion': 'gini', 'max_features': 'int', '...                NaN   \n",
       "2  {'criterion': 'gini', 'max_features': 'float',...                NaN   \n",
       "3  {'criterion': 'gini', 'max_features': 'float',...                NaN   \n",
       "4  {'criterion': 'gini', 'max_features': 'auto', ...           0.714286   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.714286           0.761905           0.619048           0.714286   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  mean_test_score  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4               0.95                0.6               0.65         0.715476   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0             NaN               20  \n",
       "1             NaN               18  \n",
       "2             NaN               17  \n",
       "3             NaN               16  \n",
       "4        0.102519                4  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(DecisionTreeClassifier(),{\n",
    "    'criterion' : [\"gini\", \"entropy\"],\n",
    "    'splitter' : [\"best\", \"random\"],\n",
    "    'max_features' : [\"int\",\"float\",\"auto\", \"sqrt\", \"log2\"]\n",
    "    }, cv=8  )\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'auto...</td>\n",
       "      <td>0.727976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.716071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'auto...</td>\n",
       "      <td>0.715476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
       "      <td>0.715476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.698214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.697321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.697024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.689881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
       "      <td>0.679464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.672619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "15  {'criterion': 'entropy', 'max_features': 'auto...         0.727976\n",
       "17  {'criterion': 'entropy', 'max_features': 'sqrt...         0.716071\n",
       "14  {'criterion': 'entropy', 'max_features': 'auto...         0.715476\n",
       "4   {'criterion': 'gini', 'max_features': 'auto', ...         0.715476\n",
       "6   {'criterion': 'gini', 'max_features': 'sqrt', ...         0.698214\n",
       "7   {'criterion': 'gini', 'max_features': 'sqrt', ...         0.697321\n",
       "16  {'criterion': 'entropy', 'max_features': 'sqrt...         0.697024\n",
       "18  {'criterion': 'entropy', 'max_features': 'log2...         0.689881\n",
       "5   {'criterion': 'gini', 'max_features': 'auto', ...         0.679464\n",
       "9   {'criterion': 'gini', 'max_features': 'log2', ...         0.672619"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['params','mean_test_score']].sort_values(by='mean_test_score', ascending=False).dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise if we wish we can run the GridsearchCv for all the models. And find out the best performing model for a particular given problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pickle','rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>0.180602</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.190635</td>\n",
       "      <td>0.193980</td>\n",
       "      <td>0.197324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.207358</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0.214047</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.224080</td>\n",
       "      <td>0.227425</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.371237</td>\n",
       "      <td>0.374582</td>\n",
       "      <td>0.377926</td>\n",
       "      <td>0.381271</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.387960</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.394649</td>\n",
       "      <td>0.397993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.401338</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.408027</td>\n",
       "      <td>0.411371</td>\n",
       "      <td>0.414716</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>0.421405</td>\n",
       "      <td>0.424749</td>\n",
       "      <td>0.428094</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568562</td>\n",
       "      <td>0.571906</td>\n",
       "      <td>0.575251</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.581940</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>0.591973</td>\n",
       "      <td>0.595318</td>\n",
       "      <td>0.598662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.602007</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.612040</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.618729</td>\n",
       "      <td>0.622074</td>\n",
       "      <td>0.625418</td>\n",
       "      <td>0.628763</td>\n",
       "      <td>0.632107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.772575</td>\n",
       "      <td>0.775920</td>\n",
       "      <td>0.779264</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.785953</td>\n",
       "      <td>0.789298</td>\n",
       "      <td>0.792642</td>\n",
       "      <td>0.795987</td>\n",
       "      <td>0.799331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.802676</td>\n",
       "      <td>0.806020</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.812709</td>\n",
       "      <td>0.816054</td>\n",
       "      <td>0.819398</td>\n",
       "      <td>0.822742</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>0.973244</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.983278</td>\n",
       "      <td>0.986622</td>\n",
       "      <td>0.989967</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000000  0.003344  0.006689  0.010033  0.013378  0.016722  0.020067   \n",
       "1  0.200669  0.204013  0.207358  0.210702  0.214047  0.217391  0.220736   \n",
       "2  0.401338  0.404682  0.408027  0.411371  0.414716  0.418060  0.421405   \n",
       "3  0.602007  0.605351  0.608696  0.612040  0.615385  0.618729  0.622074   \n",
       "4  0.802676  0.806020  0.809365  0.812709  0.816054  0.819398  0.822742   \n",
       "\n",
       "         7         8         9   ...        50        51        52        53  \\\n",
       "0  0.023411  0.026756  0.030100  ...  0.167224  0.170569  0.173913  0.177258   \n",
       "1  0.224080  0.227425  0.230769  ...  0.367893  0.371237  0.374582  0.377926   \n",
       "2  0.424749  0.428094  0.431438  ...  0.568562  0.571906  0.575251  0.578595   \n",
       "3  0.625418  0.628763  0.632107  ...  0.769231  0.772575  0.775920  0.779264   \n",
       "4  0.826087  0.829431  0.832776  ...  0.969900  0.973244  0.976589  0.979933   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.180602  0.183946  0.187291  0.190635  0.193980  0.197324  \n",
       "1  0.381271  0.384615  0.387960  0.391304  0.394649  0.397993  \n",
       "2  0.581940  0.585284  0.588629  0.591973  0.595318  0.598662  \n",
       "3  0.782609  0.785953  0.789298  0.792642  0.795987  0.799331  \n",
       "4  0.983278  0.986622  0.989967  0.993311  0.996656  1.000000  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a dummy dataframe to test the predictio of the saved model\n",
    "\n",
    "dummydf = pd.DataFrame(np.linspace(0,1,300).reshape(5,60))\n",
    "dummydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'M', 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we test the model with that dummy created data and see what it predicts\n",
    "mp.predict(dummydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try the same thing with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_joblib']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'model_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "jlmodel = joblib.load('model_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'M', 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlmodel.predict(dummydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see both pickle and joblib do the same exact things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you like my work. thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
