{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Japanese Credit Screening Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Characteristics:  Multivariate, Domain-Theory\n",
    "\n",
    "Number of Instances:125\n",
    "\n",
    "Area:Financial\n",
    "\n",
    "Attribute Characteristics:Categorical, Real, Integer\n",
    "\n",
    "Number of Attributes:N/A\n",
    "\n",
    "Date Donated: 1992-03-19\n",
    "\n",
    "Associated Tasks: Classification\n",
    "\n",
    "Missing Values?: N/A\n",
    "\n",
    "Number of Web Hits: 106034\n",
    "\n",
    "\n",
    "Source:\n",
    "Creator: Chiharu Sano\n",
    "Donor: Chiharu Sano\n",
    "csano '@' bonnie.ICS.UCI.EDU\n",
    "\n",
    "Data Set Information:\n",
    "Examples represent positive and negative instances of people who were and were not granted credit.\n",
    "The theory was generated by talking to the individuals at a Japanese company that grants credit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv(r'crx.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.columns = list(range(0,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00360</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "1  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "2  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "3  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n",
       "4  b  32.08  4.000  u  g  m  v  2.50  t  f   0  t  g  00360    0  +"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689 entries, 0 to 688\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       689 non-null    object \n",
      " 1   1       689 non-null    object \n",
      " 2   2       689 non-null    float64\n",
      " 3   3       689 non-null    object \n",
      " 4   4       689 non-null    object \n",
      " 5   5       689 non-null    object \n",
      " 6   6       689 non-null    object \n",
      " 7   7       689 non-null    float64\n",
      " 8   8       689 non-null    object \n",
      " 9   9       689 non-null    object \n",
      " 10  10      689 non-null    int64  \n",
      " 11  11      689 non-null    object \n",
      " 12  12      689 non-null    object \n",
      " 13  13      689 non-null    object \n",
      " 14  14      689 non-null    int64  \n",
      " 15  15      689 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>689.000000</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.765631</td>\n",
       "      <td>2.224819</td>\n",
       "      <td>2.402032</td>\n",
       "      <td>1018.862119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978470</td>\n",
       "      <td>3.348739</td>\n",
       "      <td>4.866180</td>\n",
       "      <td>5213.743149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           7           10             14\n",
       "count  689.000000  689.000000  689.000000     689.000000\n",
       "mean     4.765631    2.224819    2.402032    1018.862119\n",
       "std      4.978470    3.348739    4.866180    5213.743149\n",
       "min      0.000000    0.000000    0.000000       0.000000\n",
       "25%      1.000000    0.165000    0.000000       0.000000\n",
       "50%      2.750000    1.000000    0.000000       5.000000\n",
       "75%      7.250000    2.625000    3.000000     396.000000\n",
       "max     28.000000   28.500000   67.000000  100000.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14\n",
       "0  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560\n",
       "1  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824\n",
       "2  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3\n",
       "3  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0\n",
       "4  b  32.08  4.000  u  g  m  v  2.50  t  f   0  t  g  00360    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = credit.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    +\n",
       "1    +\n",
       "2    +\n",
       "3    +\n",
       "4    +\n",
       "Name: 15, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = credit.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "for col in X.columns:\n",
    "    X[col] = Encoder.fit_transform(X[col])\n",
    "y = Encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3   4   5   6   7   8   9   10  11  12  13   14\n",
       "0   1  327  93   2   1  11   4  65   1   1   6   0   0  11  119\n",
       "1   1   89  16   2   1  11   4  36   1   0   0   0   0  95  140\n",
       "2   2  125  46   2   1  13   8  73   1   1   5   1   0  31    3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689 entries, 0 to 688\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       689 non-null    int32\n",
      " 1   1       689 non-null    int32\n",
      " 2   2       689 non-null    int64\n",
      " 3   3       689 non-null    int32\n",
      " 4   4       689 non-null    int32\n",
      " 5   5       689 non-null    int32\n",
      " 6   6       689 non-null    int32\n",
      " 7   7       689 non-null    int64\n",
      " 8   8       689 non-null    int32\n",
      " 9   9       689 non-null    int32\n",
      " 10  10      689 non-null    int64\n",
      " 11  11      689 non-null    int32\n",
      " 12  12      689 non-null    int32\n",
      " 13  13      689 non-null    int32\n",
      " 14  14      689 non-null    int64\n",
      "dtypes: int32(11), int64(4)\n",
      "memory usage: 51.3 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.29396378,  1.24470288, -0.18158709, -0.44381299, -0.55126869,\n",
       "        -1.11575313,  0.75952691,  0.46577305,  0.95138759,  1.17234135,\n",
       "         1.42356708,  1.04673405, -0.30625447,  1.38027781,  2.16806186],\n",
       "       [-1.29396378, -0.62934998,  1.78717331, -0.44381299, -0.55126869,\n",
       "         0.95533676, -0.79335526, -0.0233986 , -1.05109633, -0.85299388,\n",
       "        -0.5725328 , -0.95535251, -0.30625447,  0.73069951, -0.72369691],\n",
       "       [-1.29396378,  0.49508174,  1.5495643 , -0.44381299, -0.55126869,\n",
       "         0.95533676, -0.79335526,  2.34093105,  0.95138759,  1.17234135,\n",
       "         1.42356708, -0.95535251, -0.30625447, -1.25994366,  2.35055149],\n",
       "       [ 0.67351427,  0.54713876, -1.16596729,  1.59349996,  1.74926385,\n",
       "         1.41557896,  0.75952691, -0.81150848, -1.05109633, -0.85299388,\n",
       "        -0.5725328 ,  1.04673405, -0.30625447,  0.85642434, -0.70965925],\n",
       "       [-1.29396378, -1.06662898,  1.26103907, -0.44381299, -0.55126869,\n",
       "        -0.88563203, -0.79335526, -0.78433228,  0.95138759,  1.17234135,\n",
       "        -0.32302031,  1.04673405, -0.30625447, -0.77799848, -0.24641634]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65263001,  0.66417355,  0.21129673,  1.77699559,  1.86440639,\n",
       "         0.65804974,  0.8101418 , -0.81111658,  0.96673649,  1.12903732,\n",
       "         1.87708263,  1.18616051, -0.34267572,  0.99214174, -0.76711683],\n",
       "       [ 0.65263001,  1.99038503,  2.1540805 , -0.47967979, -0.5252662 ,\n",
       "         1.84667362, -0.71094076,  2.65897289,  0.96673649,  1.12903732,\n",
       "         1.63286132,  1.18616051, -0.34267572, -1.17670751,  1.19997532],\n",
       "       [-1.30526001,  1.77987527,  2.01653828, -0.47967979, -0.5252662 ,\n",
       "         0.42032497, -1.0912114 , -0.98177672,  0.96673649,  1.12903732,\n",
       "         3.09818918, -0.84305623, -0.34267572, -1.17670751,  0.36825179],\n",
       "       [ 0.65263001,  0.77995391, -0.97500486, -0.47967979, -0.5252662 ,\n",
       "        -1.00602369,  0.8101418 , -0.72578651, -1.03440804,  1.12903732,\n",
       "        -0.07668785, -0.84305623, -0.34267572,  0.42907511,  0.7379067 ],\n",
       "       [ 0.65263001,  1.17992246, -0.33887212, -0.47967979, -0.5252662 ,\n",
       "         0.18260019, -1.85175268, -0.44135295,  0.96673649, -0.88571031,\n",
       "        -0.56513047, -0.84305623, -0.34267572,  2.07656636, -0.76711683]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR': LogisticRegression(), 'svm':SVC(), 'knn': KNeighborsClassifier(),\n",
    "         'DTC': DecisionTreeClassifier(), 'naivebayes': GaussianNB(), 'RFC': RandomForestClassifier()}\n",
    "\n",
    "for each in models:\n",
    "    model = models[each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "models = {'LR': LogisticRegression(), 'svm':SVC(), 'knn': KNeighborsClassifier(),\n",
    "         'DTC': DecisionTreeClassifier(), 'naivebayes': GaussianNB(), 'RFC': RandomForestClassifier()}\n",
    "\n",
    "for each in models:\n",
    "    print( models[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for model : LR\n",
      "Accuracy score: \t 0.8405797101449275\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        93\n",
      "           1       0.86      0.84      0.85       114\n",
      "\n",
      "    accuracy                           0.84       207\n",
      "   macro avg       0.84      0.84      0.84       207\n",
      "weighted avg       0.84      0.84      0.84       207\n",
      "\n",
      "confusion matrix: \n",
      " [[78 15]\n",
      " [18 96]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for model : svm\n",
      "Accuracy score: \t 0.8502415458937198\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        93\n",
      "           1       0.87      0.86      0.86       114\n",
      "\n",
      "    accuracy                           0.85       207\n",
      "   macro avg       0.85      0.85      0.85       207\n",
      "weighted avg       0.85      0.85      0.85       207\n",
      "\n",
      "confusion matrix: \n",
      " [[78 15]\n",
      " [16 98]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for model : knn\n",
      "Accuracy score: \t 0.8164251207729468\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78        93\n",
      "           1       0.80      0.89      0.84       114\n",
      "\n",
      "    accuracy                           0.82       207\n",
      "   macro avg       0.82      0.81      0.81       207\n",
      "weighted avg       0.82      0.82      0.81       207\n",
      "\n",
      "confusion matrix: \n",
      " [[ 68  25]\n",
      " [ 13 101]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for model : DTC\n",
      "Accuracy score: \t 0.8309178743961353\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        93\n",
      "           1       0.82      0.89      0.85       114\n",
      "\n",
      "    accuracy                           0.83       207\n",
      "   macro avg       0.83      0.82      0.83       207\n",
      "weighted avg       0.83      0.83      0.83       207\n",
      "\n",
      "confusion matrix: \n",
      " [[ 71  22]\n",
      " [ 13 101]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for model : naivebayes\n",
      "Accuracy score: \t 0.8164251207729468\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79        93\n",
      "           1       0.82      0.86      0.84       114\n",
      "\n",
      "    accuracy                           0.82       207\n",
      "   macro avg       0.82      0.81      0.81       207\n",
      "weighted avg       0.82      0.82      0.82       207\n",
      "\n",
      "confusion matrix: \n",
      " [[71 22]\n",
      " [16 98]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for model : RFC\n",
      "Accuracy score: \t 0.8599033816425121\n",
      "classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        93\n",
      "           1       0.86      0.89      0.88       114\n",
      "\n",
      "    accuracy                           0.86       207\n",
      "   macro avg       0.86      0.86      0.86       207\n",
      "weighted avg       0.86      0.86      0.86       207\n",
      "\n",
      "confusion matrix: \n",
      " [[ 76  17]\n",
      " [ 12 102]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in models:\n",
    "    model =  models[each]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypred = model.predict(X_test)\n",
    "    print(\"for model :\", each)\n",
    "    print(\"Accuracy score: \\t\", accuracy_score(y_test, ypred))\n",
    "    print(\"classification report: \\n\\n\", classification_report(y_test, ypred))\n",
    "    print(\"confusion matrix: \\n\", confusion_matrix(y_test, ypred))\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    #sns.heatmap(confusion_matrix(y_test, ypred), annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if we can do hypertuning of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\achie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "best parameter:  {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "best score:  0.8671176975945019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.867118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.867118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.867118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.867118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.867096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_multi_class param_penalty param_solver  mean_test_score\n",
       "48       multinomial            l2         saga         0.867118\n",
       "47       multinomial            l2          sag         0.867118\n",
       "49       multinomial            l2        lbfgs         0.867118\n",
       "46       multinomial            l2    newton-cg         0.867118\n",
       "3               auto            l1         saga         0.867096\n",
       "26               ovr            l2    newton-cg         0.867096\n",
       "25               ovr            l2    liblinear         0.867096\n",
       "23               ovr            l1         saga         0.867096\n",
       "43       multinomial            l1         saga         0.867096\n",
       "27               ovr            l2          sag         0.867096"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = GridSearchCV(LogisticRegression(max_iter=1000), {\n",
    "    'solver': ['liblinear', 'newton-cg', 'sag', 'saga' , 'lbfgs'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'multi_class' : ['auto', 'ovr', 'multinomial']},\n",
    "    cv = 5\n",
    "     )\n",
    "clf_LR.fit(X_train, y_train)\n",
    "df_LR = pd.DataFrame(clf_LR.cv_results_)\n",
    "print(\"best estimator: \", clf_LR.best_estimator_)\n",
    "print(\"best parameter: \", clf_LR.best_params_)\n",
    "print(\"best score: \", clf_LR.best_score_)\n",
    "df_LR.head()\n",
    "df_LR[['param_multi_class','param_penalty', 'param_solver','mean_test_score']].sort_values(by='mean_test_score', ascending=False).dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-run the model with best parameters and then save the model as pickle or joblib object, then we predict our model using dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, previously values were:\n",
    "    \n",
    "    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8405797101449275\n"
     ]
    }
   ],
   "source": [
    "clfLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "clfLR.fit(X_train,y_train)\n",
    "ypred = clfLR.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an improvement in the accuracy upto 86.7% from 84%. Now we can use joblib to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving model with pickle\n",
    "\n",
    "with open('Credit_screening_LR', 'wb') as f:\n",
    "    pickle.dump(clfLR, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Credit_screening_LR','rb') as f:\n",
    "    ClfLR = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create some random values to test the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.046823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>0.060201</td>\n",
       "      <td>0.063545</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.070234</td>\n",
       "      <td>0.073579</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>0.083612</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.090301</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.096990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100334</td>\n",
       "      <td>0.103679</td>\n",
       "      <td>0.107023</td>\n",
       "      <td>0.110368</td>\n",
       "      <td>0.113712</td>\n",
       "      <td>0.117057</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.123746</td>\n",
       "      <td>0.127090</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.133779</td>\n",
       "      <td>0.137124</td>\n",
       "      <td>0.140468</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.147157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150502</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.157191</td>\n",
       "      <td>0.160535</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>0.180602</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.190635</td>\n",
       "      <td>0.193980</td>\n",
       "      <td>0.197324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.207358</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0.214047</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.224080</td>\n",
       "      <td>0.227425</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.234114</td>\n",
       "      <td>0.237458</td>\n",
       "      <td>0.240803</td>\n",
       "      <td>0.244147</td>\n",
       "      <td>0.247492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.003344  0.006689  0.010033  0.013378  0.016722  0.020067   \n",
       "1  0.050167  0.053512  0.056856  0.060201  0.063545  0.066890  0.070234   \n",
       "2  0.100334  0.103679  0.107023  0.110368  0.113712  0.117057  0.120401   \n",
       "3  0.150502  0.153846  0.157191  0.160535  0.163880  0.167224  0.170569   \n",
       "4  0.200669  0.204013  0.207358  0.210702  0.214047  0.217391  0.220736   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.023411  0.026756  0.030100  0.033445  0.036789  0.040134  0.043478   \n",
       "1  0.073579  0.076923  0.080268  0.083612  0.086957  0.090301  0.093645   \n",
       "2  0.123746  0.127090  0.130435  0.133779  0.137124  0.140468  0.143813   \n",
       "3  0.173913  0.177258  0.180602  0.183946  0.187291  0.190635  0.193980   \n",
       "4  0.224080  0.227425  0.230769  0.234114  0.237458  0.240803  0.244147   \n",
       "\n",
       "         14  \n",
       "0  0.046823  \n",
       "1  0.096990  \n",
       "2  0.147157  \n",
       "3  0.197324  \n",
       "4  0.247492  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummydf = pd.DataFrame(np.linspace(0,1,300).reshape(20,15))\n",
    "dummydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClfLR.predict(dummydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we can do hyper parameter tuning and model deployment for all fitted models. We will do the same process for RandomForestClassifier as it resulted in best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "best parameter:  {'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "best score:  0.8962843642611684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154012</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.885889</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289530</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>3.999186e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875558</td>\n",
       "      <td>0.028271</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.437233</td>\n",
       "      <td>0.023304</td>\n",
       "      <td>0.025801</td>\n",
       "      <td>1.165861e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.890056</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552841</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.034002</td>\n",
       "      <td>6.328627e-04</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.883849</td>\n",
       "      <td>0.027070</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.692450</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.044804</td>\n",
       "      <td>6.114565e-03</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.881765</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.154012      0.018581         0.009000    6.810597e-07   \n",
       "1       0.289530      0.013849         0.019001    3.999186e-03   \n",
       "2       0.437233      0.023304         0.025801    1.165861e-03   \n",
       "3       0.552841      0.013791         0.034002    6.328627e-04   \n",
       "4       0.692450      0.008523         0.044804    6.114565e-03   \n",
       "\n",
       "  param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "0            gini            None               auto                100   \n",
       "1            gini            None               auto                200   \n",
       "2            gini            None               auto                300   \n",
       "3            gini            None               auto                400   \n",
       "4            gini            None               auto                500   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_depth': None, 'max_...           0.855670   \n",
       "1  {'criterion': 'gini', 'max_depth': None, 'max_...           0.824742   \n",
       "2  {'criterion': 'gini', 'max_depth': None, 'max_...           0.845361   \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'max_...           0.835052   \n",
       "4  {'criterion': 'gini', 'max_depth': None, 'max_...           0.835052   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.917526           0.885417           0.895833           0.875000   \n",
       "1           0.907216           0.875000           0.895833           0.875000   \n",
       "2           0.927835           0.895833           0.895833           0.885417   \n",
       "3           0.917526           0.895833           0.885417           0.885417   \n",
       "4           0.917526           0.885417           0.885417           0.885417   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.885889        0.020648               12  \n",
       "1         0.875558        0.028271               41  \n",
       "2         0.890056        0.026507                5  \n",
       "3         0.883849        0.027070               15  \n",
       "4         0.881765        0.026461               20  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFC = GridSearchCV(RandomForestClassifier(),{\n",
    "                         \n",
    "         'criterion':['gini','entropy'], \n",
    "         'max_depth':[None, 2,4],\n",
    "         'max_features':['auto','sqrt','log2'],                     \n",
    "         'n_estimators':[100,200,300,400,500],\n",
    "         \n",
    "}, cv=5\n",
    "                      )\n",
    "\n",
    "clf_RFC.fit(X_train, y_train)\n",
    "df_RFC = pd.DataFrame(clf_RFC.cv_results_)\n",
    "print(\"best estimator: \", clf_RFC.best_estimator_)\n",
    "print(\"best parameter: \", clf_RFC.best_params_)\n",
    "print(\"best score: \", clf_RFC.best_score_)\n",
    "df_RFC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy has increased up to 89.62% from 86%. We will re-run the model with new parameters and then save our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8647342995169082\n"
     ]
    }
   ],
   "source": [
    "clfRFC = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=None, max_features='log2',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "clfRFC.fit(X_train,y_train)\n",
    "ypred = clfRFC.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use ANN on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 2/100\n",
      "482/482 [==============================] - 0s 454us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 3/100\n",
      "482/482 [==============================] - 0s 461us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 4/100\n",
      "482/482 [==============================] - 0s 469us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 5/100\n",
      "482/482 [==============================] - 0s 488us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 6/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 7/100\n",
      "482/482 [==============================] - 0s 463us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 8/100\n",
      "482/482 [==============================] - 0s 467us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 9/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 10/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 11/100\n",
      "482/482 [==============================] - 0s 473us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 12/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 13/100\n",
      "482/482 [==============================] - 0s 459us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 14/100\n",
      "482/482 [==============================] - 0s 473us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 15/100\n",
      "482/482 [==============================] - 0s 477us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 16/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 17/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 18/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 19/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 20/100\n",
      "482/482 [==============================] - 0s 461us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 21/100\n",
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 22/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 23/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 24/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 25/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 26/100\n",
      "482/482 [==============================] - 0s 527us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 27/100\n",
      "482/482 [==============================] - 0s 536us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 28/100\n",
      "482/482 [==============================] - 0s 469us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 29/100\n",
      "482/482 [==============================] - 0s 494us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 30/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 31/100\n",
      "482/482 [==============================] - 0s 504us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 32/100\n",
      "482/482 [==============================] - 0s 539us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 33/100\n",
      "482/482 [==============================] - 0s 504us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 34/100\n",
      "482/482 [==============================] - 0s 556us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 35/100\n",
      "482/482 [==============================] - 0s 477us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 36/100\n",
      "482/482 [==============================] - 0s 562us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 37/100\n",
      "482/482 [==============================] - 0s 517us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 38/100\n",
      "482/482 [==============================] - 0s 490us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 39/100\n",
      "482/482 [==============================] - 0s 601us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 40/100\n",
      "482/482 [==============================] - 0s 488us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 41/100\n",
      "482/482 [==============================] - 0s 492us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 42/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 43/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 44/100\n",
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 45/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 46/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 47/100\n",
      "482/482 [==============================] - 0s 492us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 48/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 49/100\n",
      "482/482 [==============================] - 0s 544us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 50/100\n",
      "482/482 [==============================] - 0s 521us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 51/100\n",
      "482/482 [==============================] - 0s 504us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 52/100\n",
      "482/482 [==============================] - 0s 531us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 53/100\n",
      "482/482 [==============================] - 0s 506us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 54/100\n",
      "482/482 [==============================] - 0s 461us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 55/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 56/100\n",
      "482/482 [==============================] - 0s 467us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 57/100\n",
      "482/482 [==============================] - 0s 473us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 58/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 59/100\n",
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 60/100\n",
      "482/482 [==============================] - 0s 477us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 61/100\n",
      "482/482 [==============================] - 0s 463us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 62/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 63/100\n",
      "482/482 [==============================] - 0s 461us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 64/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 65/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 66/100\n",
      "482/482 [==============================] - 0s 473us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 67/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 68/100\n",
      "482/482 [==============================] - 0s 477us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 69/100\n",
      "482/482 [==============================] - 0s 473us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 70/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 71/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 72/100\n",
      "482/482 [==============================] - 0s 488us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 73/100\n",
      "482/482 [==============================] - 0s 504us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 74/100\n",
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 75/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 76/100\n",
      "482/482 [==============================] - 0s 481us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 77/100\n",
      "482/482 [==============================] - 0s 500us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 78/100\n",
      "482/482 [==============================] - 0s 483us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 80/100\n",
      "482/482 [==============================] - 0s 523us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 81/100\n",
      "482/482 [==============================] - 0s 504us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 82/100\n",
      "482/482 [==============================] - 0s 469us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 83/100\n",
      "482/482 [==============================] - 0s 510us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 84/100\n",
      "482/482 [==============================] - 0s 537us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 85/100\n",
      "482/482 [==============================] - 0s 525us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 86/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 87/100\n",
      "482/482 [==============================] - 0s 479us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 88/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 89/100\n",
      "482/482 [==============================] - 0s 490us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 90/100\n",
      "482/482 [==============================] - 0s 463us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 91/100\n",
      "482/482 [==============================] - 0s 486us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 92/100\n",
      "482/482 [==============================] - 0s 500us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 93/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 94/100\n",
      "482/482 [==============================] - 0s 463us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 95/100\n",
      "482/482 [==============================] - 0s 475us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 96/100\n",
      "482/482 [==============================] - 0s 471us/step - loss: 8.6085 - accuracy: 0.44190s - loss: 8.7702 - accuracy: 0.\n",
      "Epoch 97/100\n",
      "482/482 [==============================] - 0s 469us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 98/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 99/100\n",
      "482/482 [==============================] - 0s 465us/step - loss: 8.6085 - accuracy: 0.4419\n",
      "Epoch 100/100\n",
      "482/482 [==============================] - 0s 461us/step - loss: 8.6085 - accuracy: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x211be153e88>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train,y_train, batch_size=10, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat = (yhat > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.4492753623188406\n",
      "Confusion matrix:  [[ 93   0]\n",
      " [114   0]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        93\n",
      "           1       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.45       207\n",
      "   macro avg       0.22      0.50      0.31       207\n",
      "weighted avg       0.20      0.45      0.28       207\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Accuracy score: \", accuracy_score(y_test, yhat))\n",
    "print(\"Confusion matrix: \", confusion_matrix(y_test, yhat))\n",
    "sns.heatmap(confusion_matrix(y_test, ypred), annot=True, fmt='g')\n",
    "print(\"Classification report: \\n\", classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the model has performed poorly. In this case our best choice is RandomForest Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
